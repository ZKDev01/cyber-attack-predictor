{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de Ciberataques con AutoML\n",
    "\n",
    "Este notebook implementa un proceso de AutoML para la predicción de ciberataques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Importación de PyCaret para AutoML\n",
    "from pycaret.classification import *\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga y Exploración de Datos\n",
    "\n",
    "En esta sección, cargaremos un conjunto de datos de ejemplo para la predicción de ciberataques. Para un MVP, utilizaremos un dataset sintético."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para generar datos sintéticos de ciberataques\n",
    "def generate_synthetic_data(n_samples=1000):\n",
    "  \"\"\"Genera datos sintéticos para simular características de ciberataques.\n",
    "  \n",
    "  Args:\n",
    "    n_samples: Número de muestras a generar\n",
    "    \n",
    "  Returns:\n",
    "    DataFrame con datos sintéticos\n",
    "  \"\"\"\n",
    "  # Características simuladas de tráfico de red\n",
    "  np.random.seed(42)\n",
    "  \n",
    "  # Generamos características que podrían ser relevantes para detectar ciberataques\n",
    "  data = {\n",
    "    'packet_rate': np.random.exponential(scale=100, size=n_samples),  # Tasa de paquetes por segundo\n",
    "    'avg_packet_size': np.random.normal(loc=500, scale=150, size=n_samples),  # Tamaño promedio de paquetes\n",
    "    'connection_duration': np.random.exponential(scale=30, size=n_samples),  # Duración de conexión en segundos\n",
    "    'port_number': np.random.randint(1, 65536, size=n_samples),  # Número de puerto\n",
    "    'protocol_type': np.random.choice(['TCP', 'UDP', 'ICMP'], size=n_samples, p=[0.7, 0.2, 0.1]),  # Tipo de protocolo\n",
    "    'src_bytes': np.random.exponential(scale=1000, size=n_samples),  # Bytes enviados desde origen\n",
    "    'dst_bytes': np.random.exponential(scale=2000, size=n_samples),  # Bytes enviados desde destino\n",
    "    'login_attempts': np.random.poisson(lam=0.5, size=n_samples),  # Intentos de inicio de sesión\n",
    "    'num_failed_logins': np.random.poisson(lam=0.2, size=n_samples),  # Número de inicios de sesión fallidos\n",
    "    'num_compromised': np.random.poisson(lam=0.1, size=n_samples),  # Número de condiciones comprometidas\n",
    "    'root_shell': np.random.binomial(1, 0.05, size=n_samples),  # Si se obtuvo shell de root\n",
    "    'num_root': np.random.poisson(lam=0.1, size=n_samples),  # Número de accesos root\n",
    "    'num_file_creations': np.random.poisson(lam=1, size=n_samples),  # Número de operaciones de creación de archivos\n",
    "    'num_shells': np.random.poisson(lam=0.01, size=n_samples),  # Número de prompts de shell\n",
    "    'num_access_files': np.random.poisson(lam=0.5, size=n_samples),  # Número de operaciones en archivos de control de acceso\n",
    "    'count': np.random.poisson(lam=5, size=n_samples),  # Número de conexiones al mismo host\n",
    "    'srv_count': np.random.poisson(lam=3, size=n_samples),  # Número de conexiones al mismo servicio\n",
    "    'serror_rate': np.random.beta(0.5, 10, size=n_samples),  # Porcentaje de conexiones con errores SYN\n",
    "    'srv_serror_rate': np.random.beta(0.5, 10, size=n_samples),  # Porcentaje de conexiones con errores SYN al mismo servicio\n",
    "    'rerror_rate': np.random.beta(0.5, 10, size=n_samples),  # Porcentaje de conexiones con errores REJ\n",
    "    'srv_rerror_rate': np.random.beta(0.5, 10, size=n_samples),  # Porcentaje de conexiones con errores REJ al mismo servicio\n",
    "    'same_srv_rate': np.random.beta(5, 1, size=n_samples),  # Porcentaje de conexiones al mismo servicio\n",
    "    'diff_srv_rate': np.random.beta(1, 5, size=n_samples),  # Porcentaje de conexiones a diferentes servicios\n",
    "    'dst_host_count': np.random.poisson(lam=10, size=n_samples),  # Número de conexiones al mismo host destino\n",
    "    'dst_host_srv_count': np.random.poisson(lam=8, size=n_samples)  # Número de conexiones al mismo servicio destino\n",
    "  }\n",
    "  \n",
    "  # Creamos el DataFrame\n",
    "  df = pd.DataFrame(data)\n",
    "  \n",
    "  # Convertimos protocol_type a variables dummy\n",
    "  df = pd.get_dummies(df, columns=['protocol_type'], drop_first=True)\n",
    "  \n",
    "  # Generamos la variable objetivo (ataque o no ataque)\n",
    "  # Usamos una combinación de características para determinar si es un ataque\n",
    "  prob_attack = (0.01 + \n",
    "                 0.1 * (df['serror_rate'] > 0.2) + \n",
    "                 0.1 * (df['rerror_rate'] > 0.2) + \n",
    "                 0.1 * (df['num_failed_logins'] > 0) + \n",
    "                 0.2 * (df['num_compromised'] > 0) + \n",
    "                 0.2 * (df['root_shell'] > 0) + \n",
    "                 0.1 * (df['num_root'] > 0) + \n",
    "                 0.1 * (df['num_shells'] > 0) + \n",
    "                 0.05 * (df['packet_rate'] > 300))\n",
    "  \n",
    "  df['attack'] = np.random.binomial(1, prob_attack)\n",
    "  \n",
    "  # Añadimos algunos tipos de ataques para los casos positivos\n",
    "  attack_types = ['DoS', 'Probe', 'R2L', 'U2R']\n",
    "  df['attack_type'] = 'normal'\n",
    "  attack_mask = df['attack'] == 1\n",
    "  df.loc[attack_mask, 'attack_type'] = np.random.choice(attack_types, size=attack_mask.sum())\n",
    "  \n",
    "  return df\n",
    "\n",
    "# Generamos los datos sintéticos\n",
    "df = generate_synthetic_data(n_samples=5000)\n",
    "\n",
    "# Mostramos las primeras filas del DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información básica del dataset\n",
    "print(f\"Dimensiones del dataset: {df.shape}\")\n",
    "print(f\"\\nDistribución de la variable objetivo (attack):\\n{df['attack'].value_counts(normalize=True) * 100}\")\n",
    "print(f\"\\nDistribución de tipos de ataque:\\n{df['attack_type'].value_counts()}\")\n",
    "\n",
    "# Estadísticas descriptivas\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la distribución de ataques\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x='attack', data=df)\n",
    "plt.title('Distribución de Ataques')\n",
    "plt.xlabel('Es Ataque (1=Sí, 0=No)')\n",
    "plt.ylabel('Cantidad')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "attack_counts = df['attack_type'].value_counts()\n",
    "sns.barplot(x=attack_counts.index, y=attack_counts.values)\n",
    "plt.title('Tipos de Ataques')\n",
    "plt.xlabel('Tipo de Ataque')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de correlación\n",
    "plt.figure(figsize=(20, 16))\n",
    "corr_matrix = df.drop(['attack_type'], axis=1).corr()\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=False, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Matriz de Correlación de Características', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# Correlación con la variable objetivo\n",
    "corr_with_target = corr_matrix['attack'].sort_values(ascending=False)\n",
    "print(\"\\nCorrelación con la variable objetivo (attack):\")\n",
    "print(corr_with_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos características y variable objetivo\n",
    "X = df.drop(['attack', 'attack_type'], axis=1)\n",
    "y = df['attack']\n",
    "\n",
    "# División en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Dimensiones de X_train: {X_train.shape}\")\n",
    "print(f\"Dimensiones de X_test: {X_test.shape}\")\n",
    "print(f\"Distribución de clases en entrenamiento:\\n{y_train.value_counts(normalize=True) * 100}\")\n",
    "print(f\"Distribución de clases en prueba:\\n{y_test.value_counts(normalize=True) * 100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Proceso de AutoML con PyCaret\n",
    "\n",
    "Utilizaremos PyCaret para automatizar el proceso de selección y optimización de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparamos los datos para PyCaret\n",
    "# Combinamos X_train e y_train para el setup de PyCaret\n",
    "train_data = X_train.copy()\n",
    "train_data['attack'] = y_train\n",
    "\n",
    "# Inicializamos el experimento de clasificación\n",
    "clf_setup = setup(\n",
    "  data=train_data,\n",
    "  target='attack',\n",
    "  train_size=0.7,  # 70% para entrenamiento, 30% para validación interna\n",
    "  normalize=True,  # Normalización de características\n",
    "  transformation=True,  # Transformación de características\n",
    "  ignore_features=None,  # No ignoramos ninguna característica\n",
    "  session_id=42,  # Para reproducibilidad\n",
    "  silent=True,  # No mostrar mensajes de progreso\n",
    "  verbose=True  # Mostrar resultados detallados\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparamos todos los modelos disponibles\n",
    "best_models = compare_models(\n",
    "  fold=5,  # Validación cruzada con 5 folds\n",
    "  sort='Accuracy',  # Ordenar por precisión\n",
    "  n_select=5  # Seleccionar los 5 mejores modelos\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizamos el mejor modelo\n",
    "best_model = best_models[0] if isinstance(best_models, list) else best_models\n",
    "print(f\"Mejor modelo: {best_model}\")\n",
    "\n",
    "# Evaluamos el modelo\n",
    "evaluate_model(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos hiperparámetros del mejor modelo\n",
    "tuned_model = tune_model(\n",
    "  best_model,\n",
    "  n_iter=50,  # Número de iteraciones para la búsqueda\n",
    "  optimize='Accuracy',  # Métrica a optimizar\n",
    "  search_library='optuna',  # Biblioteca de búsqueda\n",
    "  choose_better=True  # Elegir el modelo con mejor rendimiento\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretación del modelo\n",
    "interpret_model(tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones en el conjunto de prueba\n",
    "holdout_predictions = predict_model(tuned_model, data=X_test)\n",
    "\n",
    "# Evaluación en el conjunto de prueba\n",
    "print(\"\\nRendimiento en el conjunto de prueba:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, holdout_predictions['prediction'])}\")\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(y_test, holdout_predictions['prediction']))\n",
    "\n",
    "# Matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, holdout_predictions['prediction'])\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ensamblaje de Modelos\n",
    "\n",
    "Crearemos un modelo de ensamblaje para mejorar el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un modelo de ensamblaje (blending)\n",
    "if isinstance(best_models, list) and len(best_models) > 1:\n",
    "  blender = blend_models(\n",
    "    estimator_list=best_models[:3],  # Usamos los 3 mejores modelos\n",
    "    method='soft',  # Votación suave (probabilidades)\n",
    "    optimize='Accuracy'  # Métrica a optimizar\n",
    "  )\n",
    "  \n",
    "  # Evaluamos el modelo de ensamblaje\n",
    "  print(\"\\nRendimiento del modelo de ensamblaje:\")\n",
    "  evaluate_model(blender)\n",
    "  \n",
    "  # Predicciones con el modelo de ensamblaje\n",
    "  ensemble_predictions = predict_model(blender, data=X_test)\n",
    "  \n",
    "  print(f\"Accuracy del ensamblaje: {accuracy_score(y_test, ensemble_predictions['prediction'])}\")\n",
    "  print(\"\\nInforme de clasificación del ensamblaje:\")\n",
    "  print(classification_report(y_test, ensemble_predictions['prediction']))\n",
    "else:\n",
    "  print(\"No hay suficientes modelos para crear un ensamblaje.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Guardado del Modelo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos el modelo final (puede ser el modelo ajustado o el ensamblaje)\n",
    "final_model = blender if 'blender' in locals() else tuned_model\n",
    "\n",
    "# Finalizamos el modelo (entrenamiento en todos los datos)\n",
    "final_model = finalize_model(final_model)\n",
    "\n",
    "# Guardamos el modelo\n",
    "save_model(final_model, '../models/cyberattack_predictor_model')\n",
    "\n",
    "print(\"Modelo guardado exitosamente en '../models/cyberattack_predictor_model'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Ejemplo de Uso del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el modelo guardado\n",
    "loaded_model = load_model('../models/cyberattack_predictor_model')\n",
    "\n",
    "# Generamos algunos datos de ejemplo para predicción\n",
    "example_data = generate_synthetic_data(n_samples=10).drop(['attack', 'attack_type'], axis=1)\n",
    "\n",
    "# Realizamos predicciones\n",
    "predictions = predict_model(loaded_model, data=example_data)\n",
    "\n",
    "# Mostramos las predicciones\n",
    "print(\"Predicciones para datos de ejemplo:\")\n",
    "print(predictions[['prediction_label', 'prediction_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusiones\n",
    "\n",
    "En este notebook, hemos implementado un proceso completo de AutoML para la predicción de ciberataques:\n",
    "\n",
    "1. Generamos datos sintéticos para simular características de ciberataques\n",
    "2. Exploramos y visualizamos los datos\n",
    "3. Utilizamos PyCaret para automatizar la selección y optimización de modelos\n",
    "4. Evaluamos el rendimiento de los modelos\n",
    "5. Creamos un modelo de ensamblaje para mejorar el rendimiento\n",
    "6. Guardamos el modelo final para su uso en producción\n",
    "\n",
    "Este MVP proporciona una base sólida para la predicción de ciberataques que puede ser mejorada con datos reales y características adicionales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
