{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55def820",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Demo reproducible del ADL-WAF (DecisionTree layer1 + SVM+TFIDF layer2).\n",
    "- Soporta ejecución sobre datasets locales (CSV) o demo sintética si no hay datos.\n",
    "- Ajuste: si usa datasets reales, modifique la sección `load_real_data()` para adaptar columnas.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix, classification_report\n",
    "import joblib\n",
    "import urllib.parse\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa0c341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Utilidades: generación demo (si no hay datos reales)\n",
    "# --------------------------\n",
    "def make_benign_payload():\n",
    "    words = [\"user\",\"name\",\"profile\",\"home\",\"index\",\"view\",\"param\",\"id\",\"login\",\"order\",\"item\",\"product\"]\n",
    "    return \" \".join(random.choices(words, k=random.randint(3,8)))\n",
    "\n",
    "def make_sql_injection():\n",
    "    templates = [\n",
    "        \"SELECT * FROM users WHERE id = {} OR 1=1;\".format(random.randint(1,100)),\n",
    "        \"' OR '1'='1' -- \",\n",
    "        \"'; DROP TABLE users; --\",\n",
    "        \"admin'--\",\n",
    "        \"UNION SELECT username, password FROM users --\"\n",
    "    ]\n",
    "    return random.choice(templates)\n",
    "\n",
    "def make_xss():\n",
    "    templates = [\n",
    "        \"<script>alert('XSS')</script>\",\n",
    "        \"<img src=x onerror=alert(1)>\",\n",
    "        \"<svg/onload=alert(1)>\",\n",
    "        \"<iframe src='javascript:alert(1)'></iframe>\"\n",
    "    ]\n",
    "    return random.choice(templates)\n",
    "\n",
    "def make_path_traversal():\n",
    "    templates = [\n",
    "        \"../../etc/passwd\",\n",
    "        \"/../../../../windows/win.ini\",\n",
    "        \"../config.php\"\n",
    "    ]\n",
    "    return random.choice(templates)\n",
    "\n",
    "def inject_special_chars(base):\n",
    "    extras = [\"&&\", \"||\", \"%3C\", \"%3E\", \"<\", \">\", \"=\", \"%27\", \"%22\", \"../\", \"/*\"]\n",
    "    return base + \" \" + \" \".join(random.choices(extras, k=random.randint(1,4)))\n",
    "\n",
    "def make_synthetic_dataset(N=5000):\n",
    "    rows = []\n",
    "    for i in range(N):\n",
    "        if random.random() < 0.70:\n",
    "            payload = make_benign_payload()\n",
    "            is_anomaly = 0\n",
    "            is_threat = 0\n",
    "        else:\n",
    "            attack_type = random.choices([\"sqli\",\"xss\",\"path\",\"other\"], weights=[0.4,0.3,0.2,0.1])[0]\n",
    "            if attack_type == \"sqli\":\n",
    "                payload = make_sql_injection()\n",
    "            elif attack_type == \"xss\":\n",
    "                payload = make_xss()\n",
    "            elif attack_type == \"path\":\n",
    "                payload = make_path_traversal()\n",
    "            else:\n",
    "                payload = inject_special_chars(make_benign_payload())\n",
    "            is_anomaly = 1\n",
    "            is_threat = 1\n",
    "        # small chance of benign but anomalous (noise)\n",
    "        if is_anomaly == 0 and random.random() < 0.02:\n",
    "            payload = inject_special_chars(payload)\n",
    "            is_anomaly = 1\n",
    "            is_threat = 0\n",
    "        rows.append({\"payload\": payload, \"anomaly_label\": is_anomaly, \"threat_label\": is_threat})\n",
    "    return pd.DataFrame(rows).sample(frac=1, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f75559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Feature engineering (capa 1)\n",
    "# --------------------------\n",
    "def alnum_ratio(s):\n",
    "    if not s: return 0.0\n",
    "    alnum = sum(c.isalnum() for c in s)\n",
    "    return alnum / len(s) * 100.0\n",
    "\n",
    "def badwords_ratio(s):\n",
    "    badwords = [\"select\",\"union\",\"drop\",\"alert\",\"script\",\"onerror\",\"../\",\"etc\",\"passwd\",\"--\",\"or\",\"and\",\"1=1\"]\n",
    "    s_low = s.lower()\n",
    "    found = sum(s_low.count(bw) for bw in badwords)\n",
    "    return (found / max(1, len(s.split()))) * 100.0\n",
    "\n",
    "def special_char_ratio(s):\n",
    "    if not s: return 0.0\n",
    "    special = sum((not c.isalnum() and not c.isspace()) for c in s)\n",
    "    return special / len(s) * 100.0\n",
    "\n",
    "def illegal_special_ratio(s):\n",
    "    illegal_tokens = ['%','%3C','%3E','..','&','|',';','--','/*','*/']\n",
    "    total_special = sum((not c.isalnum() and not c.isspace()) for c in s)\n",
    "    if total_special == 0: return 0.0\n",
    "    found = sum(1 for token in illegal_tokens if token in s)\n",
    "    return found / total_special * 100.0\n",
    "\n",
    "def add_layer1_features(df):\n",
    "    df = df.copy()\n",
    "    df['alnum_ratio'] = df['payload'].apply(alnum_ratio)\n",
    "    df['badwords_ratio'] = df['payload'].apply(badwords_ratio)\n",
    "    df['special_char_ratio'] = df['payload'].apply(special_char_ratio)\n",
    "    df['illegal_special_ratio'] = df['payload'].apply(illegal_special_ratio)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6e381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_anomalias_benignas(\n",
    "    df,\n",
    "    payload_col=\"payload\",\n",
    "    anomaly_col=\"anomaly_label\",\n",
    "    threat_col=\"threat_label\",\n",
    "    ratio=0.15,\n",
    "    random_state=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Convierte una fracción de requests normales en anomalías benignas.\n",
    "    \n",
    "    Parámetros:\n",
    "    - df: DataFrame original\n",
    "    - payload_col: columna con el texto HTTP / payload\n",
    "    - anomaly_col: columna anomaly_label (0/1)\n",
    "    - threat_col: columna threat_label (0/1)\n",
    "    - ratio: porcentaje de requests normales a convertir (ej: 0.15 = 15%)\n",
    "    - random_state: semilla reproducible\n",
    "    \"\"\"\n",
    "\n",
    "    random.seed(random_state)\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Seleccionar solo tráfico normal\n",
    "    normal_idx = df[\n",
    "        (df[anomaly_col] == 0) &\n",
    "        (df[threat_col] == 0)\n",
    "    ].index\n",
    "\n",
    "    n_convert = int(len(normal_idx) * ratio)\n",
    "    if n_convert == 0:\n",
    "        return df\n",
    "\n",
    "    selected_idx = random.sample(list(normal_idx), n_convert)\n",
    "\n",
    "    def perturb_payload(payload):\n",
    "        transformations = [\n",
    "            lambda s: s + \"&&\",\n",
    "            lambda s: s.replace(\"=\", \"==\", 1),\n",
    "            lambda s: s + \"%20\",\n",
    "            lambda s: urllib.parse.quote(s, safe=\"=&?\"),\n",
    "            lambda s: s + \"@@\",\n",
    "            lambda s: s + \"??\",\n",
    "            lambda s: s.replace(\"&\", \"&&\"),\n",
    "            lambda s: s + \"%3D\"\n",
    "        ]\n",
    "        transform = random.choice(transformations)\n",
    "        return transform(payload)\n",
    "\n",
    "    for idx in selected_idx:\n",
    "        original = df.at[idx, payload_col]\n",
    "        df.at[idx, payload_col] = perturb_payload(original)\n",
    "        df.at[idx, anomaly_col] = 1\n",
    "        df.at[idx, threat_col] = 0\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3011efbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_path=\"../data/test_dataset/HttpParamsDataset/payload_full.csv\"\n",
    "\n",
    "df = pd.read_csv(real_data_path)\n",
    "df = add_layer1_features(df)\n",
    "feature_cols = ['alnum_ratio','badwords_ratio','special_char_ratio','illegal_special_ratio']\n",
    "\n",
    "df[\"anomaly_label\"] = df[\"label\"].map({\n",
    "    \"norm\": 0,\n",
    "    \"anom\": 1\n",
    "})\n",
    "\n",
    "df[\"threat_label\"] = df[\"attack_type\"].apply(\n",
    "    lambda x: 0 if x == \"norm\" else 1\n",
    ")\n",
    "\n",
    "\n",
    "# Crear anomalias\n",
    "df = crear_anomalias_benignas(df, ratio=0.15)\n",
    "\n",
    "# 3) Split\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['anomaly_label'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb27303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Train layer1 (Decision Tree)\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "  RandomForestClassifier, \n",
    "  IsolationForest\n",
    ")\n",
    "\n",
    "dt = RandomForestClassifier(\n",
    "  random_state=42,\n",
    "  n_estimators=100,  \n",
    "  class_weight='balanced_subsample',  # Mejor manejo de clases\n",
    "  max_depth=None,\n",
    "  min_samples_split=5,\n",
    "  min_samples_leaf=2\n",
    ")\n",
    "dt.fit(train_df[feature_cols], train_df['anomaly_label'])\n",
    "\n",
    "# 5) Evaluate layer1\n",
    "pred_l1_test = dt.predict(test_df[feature_cols])\n",
    "print(\"\\nLayer1 - Anomaly detection (Decision Tree) - report:\")\n",
    "print(classification_report(test_df['anomaly_label'], pred_l1_test, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76a2ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    " # 6) Prepare layer2 training using only anomalous samples from training\n",
    "train_l2 = train_df[train_df['anomaly_label'] == 1].copy()\n",
    "test_l2 = test_df[test_df['anomaly_label'] == 1].copy()\n",
    "\n",
    "print(\"TRAIN L2:\")\n",
    "print(train_l2[\"threat_label\"].value_counts())\n",
    "\n",
    "print(\"\\nTEST L2:\")\n",
    "print(test_l2[\"threat_label\"].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7e5719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(anom_norm) == 0:\n",
    "#     # degradar algunos norm a anomalía benigna\n",
    "#     benign_norm = df[df[\"anomaly_label\"] == 0].sample(200, random_state=42)\n",
    "#     benign_norm[\"anomaly_label\"] = 1\n",
    "#     benign_norm[\"threat_label\"] = 0\n",
    "\n",
    "#     train_l2 = pd.concat([train_l2, benign_norm])\n",
    "\n",
    "# anom_norm = train_l2[\n",
    "#     (train_l2[\"anomaly_label\"] == 1) &\n",
    "#     (train_l2[\"attack_type\"] == \"norm\")\n",
    "# ]\n",
    "# print(len(anom_norm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4924e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,4), analyzer='char_wb')\n",
    "\n",
    "if len(train_l2) == 0:\n",
    "    raise RuntimeError(\"No hay anomalías en el conjunto de entrenamiento para entrenar layer2 (aumente dataset o cambie split).\")\n",
    "\n",
    "X_l2_train = vectorizer.fit_transform(train_l2['payload'])\n",
    "y_l2_train = train_l2['threat_label']\n",
    "\n",
    "# 7) Entrenar SVM (modelo rápido por defecto; si desea gridsearch, activarlo)\n",
    "svc = SVC(kernel='rbf', C=10, gamma='scale', probability=False, random_state=42)\n",
    "svc.fit(X_l2_train, y_l2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eaf0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TRAIN L2:\")\n",
    "print(train_l2[\"threat_label\"].value_counts())\n",
    "\n",
    "print(\"\\nTEST L2:\")\n",
    "print(test_l2[\"threat_label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfe3baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Evaluar layer2 (sobre anomalías del test)\n",
    "if len(test_l2) > 0:\n",
    "    X_l2_test = vectorizer.transform(test_l2['payload'])\n",
    "    y_l2_test = test_l2['threat_label']\n",
    "    pred_l2 = svc.predict(X_l2_test)\n",
    "    print(\"\\nLayer2 - Threat detection (SVM) - report (solo anomalías):\")\n",
    "    print(classification_report(y_l2_test, pred_l2, digits=4))\n",
    "else:\n",
    "    print(\"No hay anomalías en el conjunto de test para evaluar layer2.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cebe172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adl_decision_row(row):\n",
    "  l1 = dt.predict([row[feature_cols].values])[0]\n",
    "  if l1 == 0:\n",
    "      return 0\n",
    "  else:\n",
    "      x = vectorizer.transform([row['payload']])\n",
    "      l2 = svc.predict(x)[0]\n",
    "      return int(l2)\n",
    "\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "test_df['adl_pred'] = test_df.apply(adl_decision_row, axis=1)\n",
    "y_true = test_df['threat_label'].values\n",
    "y_pred = test_df['adl_pred'].values\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "print(\"\\nADL-WAF combined - métricas sobre conjunto de test (threat_label):\")\n",
    "print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}\")\n",
    "print(\"Confusion matrix (TN, FP, FN, TP):\", confusion_matrix(y_true, y_pred).ravel() if confusion_matrix(y_true, y_pred).size==4 else confusion_matrix(y_true, y_pred))\n",
    "print(\"\\nEjemplo de decisiones (muestra):\")\n",
    "print(test_df[['payload','anomaly_label','threat_label','adl_pred']].sample(6, random_state=42).to_string(index=False))\n",
    "\n",
    "# 10) Guardar modelos\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "joblib.dump(dt, \"models/adl_dt_layer1.joblib\")\n",
    "joblib.dump(svc, \"models/adl_svm_layer2.joblib\")\n",
    "joblib.dump(vectorizer, \"models/adl_tfidf_vectorizer.joblib\")\n",
    "print(\"\\nModelos guardados en carpeta ./models/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d926d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ADL-WAF final:\")\n",
    "print(classification_report(\n",
    "    test_df[\"threat_label\"],\n",
    "    test_df[\"adl_pred\"]\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5145e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Main pipeline\n",
    "# --------------------------\n",
    "def main(use_real_data=False, real_data_path=None):\n",
    "    # 1) Load data\n",
    "    if use_real_data:\n",
    "        if real_data_path is None or not os.path.exists(real_data_path):\n",
    "            raise ValueError(\"Si use_real_data=True, proporcione real_data_path con un CSV válido.\")\n",
    "        df = pd.read_csv(real_data_path)\n",
    "        # Expect columns: 'payload', 'anomaly_label', 'threat_label' or adapt accordingly.\n",
    "        # Si su CSV tiene columnas distintas, ajuste aquí.\n",
    "    else:\n",
    "        print(\"No dataset real provisto: generando dataset sintético para demostración...\")\n",
    "        df = make_synthetic_dataset(N=5000)\n",
    "\n",
    "    # 2) Feature engineering\n",
    "    df = add_layer1_features(df)\n",
    "    feature_cols = ['alnum_ratio','badwords_ratio','special_char_ratio','illegal_special_ratio']\n",
    "\n",
    "    # 3) Split\n",
    "    train_df, test_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['anomaly_label'])\n",
    "\n",
    "    # 4) Train layer1 (Decision Tree)\n",
    "    dt = DecisionTreeClassifier(random_state=42, max_depth=8)\n",
    "    dt.fit(train_df[feature_cols], train_df['anomaly_label'])\n",
    "\n",
    "    # 5) Evaluate layer1\n",
    "    pred_l1_test = dt.predict(test_df[feature_cols])\n",
    "    print(\"\\nLayer1 - Anomaly detection (Decision Tree) - report:\")\n",
    "    print(classification_report(test_df['anomaly_label'], pred_l1_test, digits=4))\n",
    "\n",
    "    # 6) Prepare layer2 training using only anomalous samples from training\n",
    "    train_l2 = train_df[train_df['anomaly_label'] == 1].copy()\n",
    "    test_l2 = test_df[test_df['anomaly_label'] == 1].copy()\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,4), analyzer='char_wb')\n",
    "\n",
    "    if len(train_l2) == 0:\n",
    "        raise RuntimeError(\"No hay anomalías en el conjunto de entrenamiento para entrenar layer2 (aumente dataset o cambie split).\")\n",
    "\n",
    "    X_l2_train = vectorizer.fit_transform(train_l2['payload'])\n",
    "    y_l2_train = train_l2['threat_label']\n",
    "\n",
    "    # 7) Entrenar SVM (modelo rápido por defecto; si desea gridsearch, activarlo)\n",
    "    svc = SVC(kernel='rbf', C=10, gamma='scale', probability=False, random_state=42)\n",
    "    svc.fit(X_l2_train, y_l2_train)\n",
    "\n",
    "    # 8) Evaluar layer2 (sobre anomalías del test)\n",
    "    if len(test_l2) > 0:\n",
    "        X_l2_test = vectorizer.transform(test_l2['payload'])\n",
    "        y_l2_test = test_l2['threat_label']\n",
    "        pred_l2 = svc.predict(X_l2_test)\n",
    "        print(\"\\nLayer2 - Threat detection (SVM) - report (solo anomalías):\")\n",
    "        print(classification_report(y_l2_test, pred_l2, digits=4))\n",
    "    else:\n",
    "        print(\"No hay anomalías en el conjunto de test para evaluar layer2.\")\n",
    "\n",
    "    # 9) Evaluación combinada ADL-WAF\n",
    "    def adl_decision_row(row):\n",
    "        l1 = dt.predict([row[feature_cols].values])[0]\n",
    "        if l1 == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            x = vectorizer.transform([row['payload']])\n",
    "            l2 = svc.predict(x)[0]\n",
    "            return int(l2)\n",
    "\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    test_df['adl_pred'] = test_df.apply(adl_decision_row, axis=1)\n",
    "    y_true = test_df['threat_label'].values\n",
    "    y_pred = test_df['adl_pred'].values\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    print(\"\\nADL-WAF combined - métricas sobre conjunto de test (threat_label):\")\n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}\")\n",
    "    print(\"Confusion matrix (TN, FP, FN, TP):\", confusion_matrix(y_true, y_pred).ravel() if confusion_matrix(y_true, y_pred).size==4 else confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\nEjemplo de decisiones (muestra):\")\n",
    "    print(test_df[['payload','anomaly_label','threat_label','adl_pred']].sample(6, random_state=42).to_string(index=False))\n",
    "\n",
    "    # 10) Guardar modelos\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    joblib.dump(dt, \"models/adl_dt_layer1.joblib\")\n",
    "    joblib.dump(svc, \"models/adl_svm_layer2.joblib\")\n",
    "    joblib.dump(vectorizer, \"models/adl_tfidf_vectorizer.joblib\")\n",
    "    print(\"\\nModelos guardados en carpeta ./models/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
