{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0316b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "# Para evitar warnings de convergencia\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Agregamos importaciones para validación cruzada y fine-tuning\n",
    "from sklearn.model_selection import (\n",
    "  train_test_split,\n",
    "  StratifiedKFold,          # Validación cruzada estratificada\n",
    "  GridSearchCV,\n",
    "  RandomizedSearchCV,       # Para optimización de hiperparámetros\n",
    "  cross_val_score,\n",
    "  cross_val_predict\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "  StandardScaler,\n",
    "  RobustScaler,\n",
    "  LabelEncoder\n",
    ")\n",
    "from sklearn.tree import (\n",
    "  DecisionTreeClassifier\n",
    ")\n",
    "from sklearn.ensemble import (\n",
    "  RandomForestClassifier, \n",
    "  IsolationForest,\n",
    "  GradientBoostingClassifier, \n",
    "  AdaBoostClassifier, \n",
    "  ExtraTreesClassifier\n",
    ")\n",
    "from sklearn.linear_model import (\n",
    "  LogisticRegression\n",
    ")\n",
    "from sklearn.neighbors import (\n",
    "  KNeighborsClassifier\n",
    ")\n",
    "from sklearn.naive_bayes import (\n",
    "  GaussianNB\n",
    ")\n",
    "from xgboost import (\n",
    "  XGBClassifier\n",
    ")\n",
    "from lightgbm import (\n",
    "  LGBMClassifier\n",
    ")\n",
    "from sklearn.svm import (\n",
    "  SVC\n",
    ")\n",
    "\n",
    "from sklearn.discriminant_analysis import (\n",
    "  LinearDiscriminantAnalysis, \n",
    "  QuadraticDiscriminantAnalysis\n",
    ")\n",
    "from sklearn.neural_network import (\n",
    "  MLPClassifier\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "  classification_report, \n",
    "  confusion_matrix,\n",
    "  roc_auc_score,\n",
    "  roc_curve,\n",
    "  precision_recall_curve,\n",
    "  f1_score,\n",
    "  recall_score, \n",
    "  precision_score,\n",
    "  accuracy_score,\n",
    "  precision_recall_fscore_support   # Métricas adicionales\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Para optimización de hiperparámetros\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "\n",
    "# Configuración de estilo para las gráficas\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd750f3",
   "metadata": {},
   "source": [
    "### Carga y Exploración del Dataset Combinado\n",
    "\n",
    "Se va a entrenar un modelo sobre el dataset combinado: **Access-Log-Master** y **CSIC2010**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929ed4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_combined_path = '../data/combined/dataset_combined_master_csic2010.csv'\n",
    "df_combined = pd.read_csv(dataset_combined_path) \n",
    "display(df_combined.head(3))\n",
    "display(df_combined['anomaly'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de126a2",
   "metadata": {},
   "source": [
    "### Codificación de Variables\n",
    "\n",
    "Se tendría que codificar solamente `method`, ya que `anomaly` viene codificada con $0$ (Normal) y $1$ (Anomalía)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2034e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "df_combined['method_encoded'] = encoder.fit_transform(df_combined['method'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2571c008",
   "metadata": {},
   "source": [
    "### Preparación de Datos para Modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3fd87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feat = [\n",
    "  'url__count_sql_words', \n",
    "  'url__count_xss_words', \n",
    "  'url__count_command_words',\n",
    "  'url__count_auth_words', \n",
    "  'url__count_error_words', \n",
    "  'url__count_malware_words',\n",
    "  'url__count_danger_characters', \n",
    "  'url__count_obfuscation_code_words', \n",
    "  'url__count_dir_words',\n",
    "  'url__count_dot', \n",
    "  'url__count_http', \n",
    "  'url__count_percentage_symbol', \n",
    "  'url__count_question_symbol',\n",
    "  'url__count_hyphen', \n",
    "  'url__count_equal', \n",
    "  'url__url_length', \n",
    "  'url__digit_count',\n",
    "  'url__letter_count', \n",
    "  'url__count_special_characters', \n",
    "  'url__is_encoded', \n",
    "  'url__unusual_character_ratio'\n",
    "]\n",
    "cat_feat = ['method_encoded']\n",
    "\n",
    "X = df_combined[num_feat + cat_feat]\n",
    "X_cat = df_combined[cat_feat]\n",
    "y = df_combined['anomaly']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f816d42",
   "metadata": {},
   "source": [
    "### Escalado de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158edb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#X_scaled = scaler.fit_transform(X[num_feat])\n",
    "#X_scaled_df = pd.DataFrame(X_scaled, columns=num_feat, index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad473e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X[num_feat])\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=num_feat, index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfc17d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_scaled_df\n",
    "X[cat_feat] = X_cat[cat_feat]\n",
    "display(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672162ae",
   "metadata": {},
   "source": [
    "### Función de Evaluación y Entrenamiento de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2909e9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_scaling(model, X, y, cv=5, random_state=42):\n",
    "  \"\"\"Evalúa un modelo con escalado, SMOTE y validación cruzada estratificada.\n",
    "\n",
    "  Args:\n",
    "    model: Modelo de sklearn\n",
    "    X: Características escaladas\n",
    "    y: Etiquetas\n",
    "    cv: Número de folds\n",
    "    random_state: Parámetro de Aleatoriedad\n",
    "\n",
    "  Returns:\n",
    "    Diccionario con métricas promedio y globales\n",
    "  \"\"\"\n",
    "  skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=random_state)\n",
    "\n",
    "  # Crear pipeline (SMOTE se aplica solo durante entrenamiento)\n",
    "  pipeline = ImbPipeline([\n",
    "    ('smote', SMOTE(random_state=random_state)),\n",
    "    ('classifier', model)\n",
    "  ])\n",
    "\n",
    "  accuracies, aucs, precisions, recalls, f1_scores = [], [], [], [], []\n",
    "  y_true_all, y_pred_all, y_pred_proba_all = [], [], []\n",
    "\n",
    "  for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # Entrenar pipeline\n",
    "    with warnings.catch_warnings():\n",
    "      warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "      pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Predecir\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "    y_pred_proba = pipeline.predict_proba(X_val)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    # Métricas del fold\n",
    "    accuracies.append(accuracy_score(y_val, y_pred))\n",
    "    if y_pred_proba is not None:\n",
    "      aucs.append(roc_auc_score(y_val, y_pred_proba))\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_val, y_pred, average='binary', pos_label=1, zero_division=0)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    # Acumular para métricas globales\n",
    "    y_true_all.extend(y_val)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    if y_pred_proba is not None:\n",
    "      y_pred_proba_all.extend(y_pred_proba)\n",
    "\n",
    "  # Métricas promedio de CV\n",
    "  cv_metrics = {\n",
    "    'accuracy': f\"{np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\",\n",
    "    'auc': f\"{np.mean(aucs):.4f} ± {np.std(aucs):.4f}\" if aucs else \"N/A\",\n",
    "    'precision': f\"{np.mean(precisions):.4f} ± {np.std(precisions):.4f}\",\n",
    "    'recall': f\"{np.mean(recalls):.4f} ± {np.std(recalls):.4f}\",\n",
    "    'f1': f\"{np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\"\n",
    "  }\n",
    "\n",
    "  # Métricas globales\n",
    "  global_metrics = {\n",
    "    'accuracy': accuracy_score(y_true_all, y_pred_all),\n",
    "    'auc': roc_auc_score(y_true_all, y_pred_proba_all) if y_pred_proba_all else None,\n",
    "    'precision': precision_recall_fscore_support(y_true_all, y_pred_all, average='binary', pos_label=1, zero_division=0)[0],\n",
    "    'recall': precision_recall_fscore_support(y_true_all, y_pred_all, average='binary', pos_label=1, zero_division=0)[1],\n",
    "    'f1': precision_recall_fscore_support(y_true_all, y_pred_all, average='binary', pos_label=1, zero_division=0)[2],\n",
    "    'confusion_matrix': confusion_matrix(y_true_all, y_pred_all)\n",
    "  }\n",
    "\n",
    "  return cv_metrics, global_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff49a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable para almacenar los resultados de cada modelo de entrenamiento \n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fa4155",
   "metadata": {},
   "source": [
    "#### Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e85a78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(\n",
    "  random_state=42,\n",
    "  max_iter=1000,  \n",
    "  solver='lbfgs', \n",
    "  C=0.1,  \n",
    "  class_weight='balanced', \n",
    "  verbose=0\n",
    ")\n",
    "# Evaluación con Validación Cruzada (5 Folds)\n",
    "cv_metrics, global_metrics = evaluate_model_with_scaling(model_lr, X, y, cv=5)\n",
    "results['LogisticRegression'] = {\n",
    "  'cv': cv_metrics, \n",
    "  'global': global_metrics\n",
    "}\n",
    "print(f\"Métricas CV (promedio ± std)\")\n",
    "for metric, value in cv_metrics.items():\n",
    "  print(f\"- {metric.capitalize()}: {value}\")\n",
    "\n",
    "print(f\"\"\"Métricas totales (concatenado de todos los folds):\n",
    "- Accuracy:  {global_metrics['accuracy']:.4f}\n",
    "- Precision: {global_metrics['precision']:.4f}\n",
    "- Recall:    {global_metrics['recall']:.4f}\n",
    "- F1:        {global_metrics['f1']:.4f}\n",
    "\"\"\")\n",
    "# NO Metrica AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c797fa4c",
   "metadata": {},
   "source": [
    "#### Clasificador Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1990e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rfc = RandomForestClassifier(\n",
    "  random_state=42,\n",
    "  n_estimators=100,  \n",
    "  class_weight='balanced_subsample',  # Mejor manejo de clases\n",
    "  max_depth=None,\n",
    "  min_samples_split=5,\n",
    "  min_samples_leaf=2\n",
    ")\n",
    "# Evaluación con Validación Cruzada (5 Folds)\n",
    "cv_metrics, global_metrics = evaluate_model_with_scaling(model_rfc, X, y, cv=5)\n",
    "results['RandomForestClassifier'] = {\n",
    "  'cv': cv_metrics, \n",
    "  'global': global_metrics\n",
    "}\n",
    "print(f\"Métricas CV (promedio ± std)\")\n",
    "for metric, value in cv_metrics.items():\n",
    "  print(f\"- {metric.capitalize()}: {value}\")\n",
    "\n",
    "print(f\"\"\"Métricas totales (concatenado de todos los folds):\n",
    "- Accuracy:  {global_metrics['accuracy']:.4f}\n",
    "- Precision: {global_metrics['precision']:.4f}\n",
    "- Recall:    {global_metrics['recall']:.4f}\n",
    "- F1:        {global_metrics['f1']:.4f}\n",
    "\"\"\")\n",
    "print(f\"- AUC: {global_metrics['auc']:.4f} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa5122",
   "metadata": {},
   "source": [
    "#### Clasificador XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144b4a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgboost = XGBClassifier(\n",
    "  random_state=42,\n",
    "  eval_metric='logloss',\n",
    "  scale_pos_weight=len(y[y==0]) / len(y[y==1]), # Balancear clases\n",
    "  n_estimators=200,\n",
    "  max_depth=6,\n",
    "  learning_rate=0.1,\n",
    "  subsample=0.8,\n",
    "  colsample_bytree=0.8\n",
    ")\n",
    "# Evaluación con Validación Cruzada (5 Folds)\n",
    "cv_metrics, global_metrics = evaluate_model_with_scaling(model_xgboost, X, y, cv=5)\n",
    "results['XGBClassifier'] = {\n",
    "  'cv': cv_metrics, \n",
    "  'global': global_metrics\n",
    "}\n",
    "print(f\"Métricas CV (promedio ± std)\")\n",
    "for metric, value in cv_metrics.items():\n",
    "  print(f\"- {metric.capitalize()}: {value}\")\n",
    "\n",
    "print(f\"\"\"Métricas totales (concatenado de todos los folds):\n",
    "- Accuracy:  {global_metrics['accuracy']:.4f}\n",
    "- Precision: {global_metrics['precision']:.4f}\n",
    "- Recall:    {global_metrics['recall']:.4f}\n",
    "- F1:        {global_metrics['f1']:.4f}\n",
    "\"\"\")\n",
    "print(f\"- AUC: {global_metrics['auc']:.4f} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf15c04",
   "metadata": {},
   "source": [
    "#### Gradient Boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667d0e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grad_boosting = GradientBoostingClassifier(\n",
    "  random_state=42,\n",
    "  n_estimators=200,\n",
    "  learning_rate=0.1,\n",
    "  max_depth=5,\n",
    "  min_samples_split=10,\n",
    "  min_samples_leaf=5,\n",
    "  subsample=0.8,\n",
    "  max_features='sqrt'\n",
    ")\n",
    "# Evaluación con Validación Cruzada (5 Folds)\n",
    "cv_metrics, global_metrics = evaluate_model_with_scaling(model_grad_boosting, X, y, cv=5)\n",
    "results['GradientBoosting'] = {\n",
    "  'cv': cv_metrics, \n",
    "  'global': global_metrics\n",
    "}\n",
    "print(f\"Métricas CV (promedio ± std)\")\n",
    "for metric, value in cv_metrics.items():\n",
    "  print(f\"- {metric.capitalize()}: {value}\")\n",
    "\n",
    "print(f\"\"\"Métricas totales (concatenado de todos los folds):\n",
    "- Accuracy:  {global_metrics['accuracy']:.4f}\n",
    "- Precision: {global_metrics['precision']:.4f}\n",
    "- Recall:    {global_metrics['recall']:.4f}\n",
    "- F1:        {global_metrics['f1']:.4f}\n",
    "\"\"\")\n",
    "print(f\"- AUC: {global_metrics['auc']:.4f} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd06802",
   "metadata": {},
   "source": [
    "#### Ada Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff7fdcf",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf2f5e4",
   "metadata": {},
   "source": [
    "#### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0cf88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = SVC(\n",
    "  random_state=42,\n",
    "  kernel='linear',\n",
    "  C=1.0,\n",
    "  class_weight='balanced',\n",
    "  probability=True,  # Necesario para AUC\n",
    "  max_iter=1000,\n",
    "  verbose=0\n",
    ")\n",
    "# Evaluación con Validación Cruzada (5 Folds)\n",
    "cv_metrics, global_metrics = evaluate_model_with_scaling(model_svm, X, y, cv=5)\n",
    "results['SVM'] = {\n",
    "  'cv': cv_metrics, \n",
    "  'global': global_metrics\n",
    "}\n",
    "print(f\"Métricas CV (promedio ± std)\")\n",
    "for metric, value in cv_metrics.items():\n",
    "  print(f\"- {metric.capitalize()}: {value}\")\n",
    "\n",
    "print(f\"\"\"Métricas totales (concatenado de todos los folds):\n",
    "- Accuracy:  {global_metrics['accuracy']:.4f}\n",
    "- Precision: {global_metrics['precision']:.4f}\n",
    "- Recall:    {global_metrics['recall']:.4f}\n",
    "- F1:        {global_metrics['f1']:.4f}\n",
    "\"\"\")\n",
    "print(f\"- AUC: {global_metrics['auc']:.4f} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee36dc4",
   "metadata": {},
   "source": [
    "\n",
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b9448",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = KNeighborsClassifier(\n",
    "    n_neighbors=5,\n",
    "    weights='distance',\n",
    "    algorithm='auto',\n",
    "    leaf_size=30,\n",
    "    p=2,\n",
    "    n_jobs=-1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78546c8d",
   "metadata": {},
   "source": [
    "\n",
    "#### Naive Bayes \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a3fe5f",
   "metadata": {},
   "source": [
    "\n",
    "#### MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9716acb1",
   "metadata": {},
   "source": [
    "### Fine-Tuning con RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da95cf4",
   "metadata": {},
   "source": [
    "#### Optimización de Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10018544",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_param_dist = [\n",
    "  {  # Para penalty='l2'\n",
    "    'classifier__C': loguniform(1e-3, 1e2),\n",
    "    'classifier__solver': ['lbfgs', 'newton-cg', 'sag', 'saga'],\n",
    "    'classifier__max_iter': [2000, 3000, 5000],\n",
    "    'classifier__class_weight': [None, 'balanced'],\n",
    "    'classifier__penalty': ['l2']\n",
    "  },\n",
    "  {  # Para penalty=None (sin regularización)\n",
    "    'classifier__solver': ['lbfgs', 'newton-cg', 'sag', 'saga'],\n",
    "    'classifier__max_iter': [2000, 3000, 5000],\n",
    "    'classifier__class_weight': [None, 'balanced'],\n",
    "    'classifier__penalty': [None]\n",
    "  }\n",
    "]\n",
    "\n",
    "lr_pipeline = ImbPipeline([\n",
    "  ('smote', SMOTE(random_state=42)),\n",
    "  ('classifier', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "lr_random = RandomizedSearchCV(\n",
    "  lr_pipeline,\n",
    "  param_distributions=lr_param_dist,\n",
    "  n_iter=20,\n",
    "  cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),  # 3 folds para velocidad\n",
    "  scoring='f1',\n",
    "  refit=True,\n",
    "  n_jobs=-1,\n",
    "  verbose=0,\n",
    "  random_state=42\n",
    ")\n",
    "\n",
    "# Entrenar con warnings suprimidos\n",
    "with warnings.catch_warnings():\n",
    "  warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "  warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "  lr_random.fit(X, y)\n",
    "\n",
    "print(f\"\"\"Resultados del Fine-Tuning de Hiperparámetros de Regresión Logística (Optimización de Regresión Logística)\n",
    "Mejores Parámetros LR:  {lr_random.best_params_}\n",
    "Mejor F1-Score:         {lr_random.best_score_:.4f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba73974e",
   "metadata": {},
   "source": [
    "#### Optimización del Clasificador Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3654f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_dist = {\n",
    "  'classifier__n_estimators': randint(100, 500),\n",
    "  'classifier__max_depth': [10, 20, 30, None],\n",
    "  'classifier__min_samples_split': randint(2, 20),\n",
    "  'classifier__min_samples_leaf': randint(1, 10),\n",
    "  'classifier__max_features': ['sqrt', 'log2', None],\n",
    "  'classifier__class_weight': [None, 'balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "rf_pipeline = ImbPipeline([\n",
    "  ('smote', SMOTE(random_state=42)),\n",
    "  ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "rf_random = RandomizedSearchCV(\n",
    "  rf_pipeline,\n",
    "  param_distributions=rf_param_dist,\n",
    "  n_iter=15,\n",
    "  cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "  scoring='f1',\n",
    "  refit=True,\n",
    "  n_jobs=-1,\n",
    "  verbose=0,\n",
    "  random_state=42\n",
    ")\n",
    "\n",
    "# Proceso de Entrenamiento\n",
    "rf_random.fit(X, y)\n",
    "\n",
    "print(f\"\"\"Resultados del Fine-Tuning de Hiperparámetros del Clasificador Random Forest (Optimización del RF Classifier)\n",
    "Mejores Parámetros LR:  {rf_random.best_params_}\n",
    "Mejor F1-Score:         {rf_random.best_score_:.4f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb8f2fa",
   "metadata": {},
   "source": [
    "### Comparación y Visualización de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae9d2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos optimizados\n",
    "optimized_models = {\n",
    "  'LogisticRegression_Optimized': lr_random.best_estimator_,\n",
    "  'RandomForest_Optimized': rf_random.best_estimator_,\n",
    "  'XGBoost_Default': model_xgboost  # Ya estaba bastante configurado\n",
    "}\n",
    "\n",
    "final_results = {}\n",
    "for name, model in optimized_models.items():\n",
    "  print(f\" {name}:\")\n",
    "  cv_metrics, global_metrics = evaluate_model_with_scaling(\n",
    "    model.named_steps['classifier'] if hasattr(model, 'named_steps') else model,\n",
    "    X, y, cv=5\n",
    "  )\n",
    "  final_results[name] = {'cv': cv_metrics, 'global': global_metrics}\n",
    "  \n",
    "  print(f\"- F1-score (CV): {cv_metrics['f1']}\")\n",
    "  print(f\"- F1-score (Global): {global_metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7758eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para gráfico\n",
    "model_names = list(results.keys())\n",
    "f1_scores = [results[name]['global']['precision'] for name in model_names]\n",
    "auc_scores = [results[name]['global']['recall'] for name in model_names if results[name]['global']['auc']]\n",
    "\n",
    "# Gráfico de comparación\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Gráfico 1: F1 Scores\n",
    "axes[0].bar(model_names, f1_scores, color=['#FF6B6B', '#4ECDC4', '#45B7D1'], alpha=0.8)\n",
    "axes[0].set_title('Comparación de F1-Score (Global)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('F1-Score', fontsize=12)\n",
    "axes[0].set_ylim(0, 1)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Agregar valores encima de las barras\n",
    "for i, v in enumerate(f1_scores):\n",
    "    axes[0].text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Gráfico 2: AUC Scores\n",
    "axes[1].bar(model_names[:len(auc_scores)], auc_scores, color=['#FF6B6B', '#4ECDC4', '#45B7D1'], alpha=0.8)\n",
    "axes[1].set_title('Comparación de AUC (Global)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('AUC', fontsize=12)\n",
    "axes[1].set_ylim(0, 1)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Agregar valores encima de las barras\n",
    "for i, v in enumerate(auc_scores):\n",
    "  axes[1].text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfb38ee",
   "metadata": {},
   "source": [
    "### Guardar Mejor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c4543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import datetime\n",
    "\n",
    "# Seleccionar el mejor modelo basado en F1-score\n",
    "best_model_name = max(final_results, key=lambda x: final_results[x]['global']['f1'])\n",
    "best_model = optimized_models[best_model_name]\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"MEJOR MODELO: {best_model_name}\")\n",
    "print(f\"F1-Score: {final_results[best_model_name]['global']['f1']:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Guardar modelo y escalador\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "joblib.dump(best_model, f'../models/best_model_{timestamp}.pkl')\n",
    "joblib.dump(scaler, f'../models/scaler_{timestamp}.pkl')\n",
    "joblib.dump(method_encoder, f'../models/method_encoder_{timestamp}.pkl')\n",
    "\n",
    "print(f\"\\nModelo guardado como: best_model_{timestamp}.pkl\")\n",
    "print(f\"Escalador guardado como: scaler_{timestamp}.pkl\")\n",
    "print(f\"Encoder de métodos guardado como: method_encoder_{timestamp}.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
