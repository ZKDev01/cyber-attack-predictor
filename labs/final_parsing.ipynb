{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67af2f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "# Librerías para el procesamiento de access logs \n",
    "import re \n",
    "from parse import parse \n",
    "from lars.apache import ApacheSource, COMBINED, ApacheWarning\n",
    "\n",
    "# Manejo de advertencias del sistema, usada para capturar las líneas que no pueden parsearse por problemas de lars (ApacheWarning)\n",
    "import warnings\n",
    "\n",
    "# Configuración de estilo para las gráficas\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Ejecutar antes las celdas de `01_access_log_parsing` o elige una ubicación donde exista un archivo de access logs (Apache Combined Log Format) \n",
    "log_file_path = '../data/target/access_log_master.log'\n",
    "log_prep_path = '../data/target/access_log_master.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192c98c0",
   "metadata": {},
   "source": [
    "### Expresión General para Apache Combined Log Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41ec60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_PATTERN = re.compile(\n",
    "  r'(?P<ip_client>\\S+)\\s+'      # IP del cliente \n",
    "  r'(?P<ident>\\S+)\\s+'          # ident \n",
    "  r'(?P<auth_user>\\S+)\\s+'      # auth_user\n",
    "  r'\\[(?P<timestamp>.+?)\\]\\s+'  # timestamp\n",
    "  r'\\\"(?P<request>.*?)\\\"\\s+'    # línea completa de request: método + url + protocolo\n",
    "  r'(?P<status>\\d{3})\\s+'       # código de estado\n",
    "  r'(?P<size>\\S+)\\s+'           # tamaño de respuesta (bytes)\n",
    "  r'\\\"(?P<referer>.*?)\\\"\\s+'    # referer\n",
    "  r'\\\"(?P<user_agent>.*?)\\\"'    # user-agent\n",
    ")\n",
    "\n",
    "def parse_apache_logs(log_file_path, add_n_line:bool=False, del_request:bool=True):\n",
    "  \"Parsea logs de Apache extrayendo todos los campos solicitados\"\n",
    "  parsed_logs = []\n",
    "  failed_lines = []\n",
    "  \n",
    "  with open(log_file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "    for line_num, line in enumerate(file, 1):\n",
    "      line = line.strip()\n",
    "      if not line:\n",
    "        continue\n",
    "      \n",
    "      match = LOG_PATTERN.match(line)\n",
    "      \n",
    "      if match:\n",
    "        # Obtener todos los campos capturados\n",
    "        log_data = match.groupdict()\n",
    "        \n",
    "        # Separar request en método, URL y protocolo\n",
    "        request_parts = log_data['request'].split()\n",
    "        if len(request_parts) >= 3:\n",
    "          log_data['method'] = request_parts[0]\n",
    "          log_data['url'] = request_parts[1]\n",
    "          log_data['protocol'] = request_parts[2]\n",
    "        elif len(request_parts) == 2:\n",
    "          log_data['method'] = request_parts[0]\n",
    "          log_data['url'] = request_parts[1]\n",
    "          log_data['protocol'] = 'UNKNOWN'\n",
    "        else:\n",
    "          log_data['method'] = 'UNKNOWN'\n",
    "          log_data['url'] = 'UNKNOWN'\n",
    "          log_data['protocol'] = 'UNKNOWN'\n",
    "        \n",
    "        if add_n_line:\n",
    "          # Añadir número de línea\n",
    "          log_data['line_number'] = line_num\n",
    "        \n",
    "        if del_request:\n",
    "          del log_data['request']\n",
    "        \n",
    "        parsed_logs.append(log_data)\n",
    "      else:\n",
    "        # Guardar línea fallida\n",
    "        failed_lines.append({\n",
    "          'line': line_num,\n",
    "          'content': line[:100]\n",
    "        })\n",
    "  \n",
    "  return parsed_logs, failed_lines\n",
    "\n",
    "logs, errors = parse_apache_logs(log_file_path)\n",
    "\n",
    "print(f\"Cantidad de logs parseados: {len(logs)}\")\n",
    "print(f\"Cantidad de logs fallidos:  {len(errors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3970bdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(logs)\n",
    "\n",
    "# Columna para representar si un log es un ataque o no (inicialmente todos en False)\n",
    "df['attack'] = False \n",
    "\n",
    "display(df.head())\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d232507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(log_prep_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5805f190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformar 'timestamp' a datetime (ajustando el formato de Apache) \n",
    "def parse_apache_time(time_str):\n",
    "  \"Convierte el formato de tiempo de Apache Access Log a datetime\"\n",
    "  try:\n",
    "    # Ejemplo de formato: [01/01/2001:00:00:01 -0700]\n",
    "    return pd.to_datetime(time_str, format='%d/%b/%Y:%H:%M:%S %z', errors='coerce')\n",
    "  except: \n",
    "    return pd.NaT \n",
    "\n",
    "df['timestamp'] = df['timestamp'].apply(parse_apache_time)\n",
    "\n",
    "\n",
    "# transformar 'size' a numérico (manejando valores no numéricos como '-')\n",
    "df['size'] = pd.to_numeric(df['size'], errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11a5ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fad00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Rango de Tiempo: {df['timestamp'].min()} -> {df['timestamp'].max()}\")\n",
    "print(f\"Estadísticas de 'size': Min={ df['size'].min() }, Max={ df['size'].max() }, Mean={ df['size'].mean() }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e99df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las primeras K filas con los valores 'size' más altos\n",
    "K = 10\n",
    "display_cols = [\n",
    "  \n",
    "]\n",
    "# Ordenar por tamaño de forma descendente y tomar las primeras K filas\n",
    "top_K_largest = df.nlargest(K, 'size')\n",
    "above_mean = df[df['size'] > df['size'].mean()]\n",
    "print(f\"Logs con tamaño de respuesta > promedio (promedio/mean={df['size'].mean():.2f}): {len(above_mean)} ({(len(above_mean)/len(df))*100:.2f}%)\")\n",
    "display(top_K_largest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2102f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Crear scatter plot con transparencia para manejar muchos puntos\n",
    "plt.scatter(df['timestamp'], df['size'], alpha=0.6, s=10, color='royalblue')\n",
    "\n",
    "plt.title('Tamaño de respuestas a lo largo del tiempo', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Fecha y Hora', fontsize=12)\n",
    "plt.ylabel('Tamaño (bytes)', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
