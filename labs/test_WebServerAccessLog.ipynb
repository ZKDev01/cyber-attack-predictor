{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9e2fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "# Librerías para el procesamiento de access logs \n",
    "import re \n",
    "from parse import parse \n",
    "from lars.apache import ApacheSource, COMBINED, ApacheWarning\n",
    "\n",
    "# Manejo de advertencias del sistema, usada para capturar las líneas que no pueden parsearse por problemas de lars (ApacheWarning)\n",
    "import warnings\n",
    "\n",
    "# Configuración de estilo para las gráficas\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "log_file_path = '../data/test_dataset/WebServerAccessLog/access.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab635e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambia a None para cargar todos los datos, o a un número para establecer un límite\n",
    "n_samples = None \n",
    "\n",
    "with open(log_file_path, 'r') as f:\n",
    "  if n_samples is not None: \n",
    "    sample_lines = []\n",
    "    for _ in range(n_samples):\n",
    "      line = f.readline()\n",
    "      \n",
    "      # si se acaba el archivo antes de alcanzar el número de muestras definidas\n",
    "      if not line:    \n",
    "        break \n",
    "      sample_lines.append(line.strip())\n",
    "  else: \n",
    "    # Cargar todas las líneas\n",
    "    sample_lines = [line.strip() for line in f]\n",
    "\n",
    "print(f\"Sample log lines (Total: {len(sample_lines)}):\")\n",
    "for i,line in enumerate(sample_lines[:10], 1):\n",
    "  print(f\"{i:>{len(str(n_samples))}}) {line}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f152c453",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_logs = []\n",
    "conflicting_logs = {}\n",
    "problematic_logs = {}\n",
    "\n",
    "with open(log_file_path, 'r') as f:\n",
    "  all_lines = f.readlines()\n",
    "\n",
    "# Lista de campos de URL que se quieren extraer de la clase Row de lars\n",
    "url_fields = [\n",
    "  ('request_url_scheme', 'scheme'),\n",
    "  ('request_url_netloc', 'netloc'),\n",
    "  ('request_url_path_str', 'path_str'),\n",
    "  ('request_url_params', 'params'),\n",
    "  ('request_url_query_str', 'query_str'),\n",
    "  ('request_url_fragment', 'fragment')\n",
    "]\n",
    "\n",
    "# Función para extraer campos de URL \n",
    "def extract_url_fields(url_obj):\n",
    "  result = {}\n",
    "  for field_name, attr_name in url_fields:\n",
    "    try:\n",
    "      value = getattr(url_obj, attr_name, None)\n",
    "      result[field_name] = value if value else None\n",
    "    except Exception:\n",
    "      result[field_name] = None\n",
    "  return result\n",
    "\n",
    "with warnings.catch_warnings(record=True) as w:\n",
    "  warnings.simplefilter(\"always\", ApacheWarning)\n",
    "\n",
    "  with open(log_file_path) as f:\n",
    "    with ApacheSource(f, log_format=COMBINED) as source:\n",
    "      for i, row in enumerate(source, 1):\n",
    "        try:\n",
    "          record = {\n",
    "            \"remote_host\": row.remote_host,\n",
    "            \"ident\": row.ident,\n",
    "            \"remote_user\": row.remote_user,\n",
    "            \"time\": row.time,\n",
    "            \"request_method\": row.request.method if hasattr(row, 'request') and row.request else None,\n",
    "            \"request_protocol\": row.request.protocol if hasattr(row, 'request') and row.request else None,\n",
    "            \"status\": row.status,\n",
    "            \"size\": row.size,\n",
    "            \"req_Referer\": row.req_Referer,\n",
    "            \"req_User_agent\": row.req_User_agent,\n",
    "          }\n",
    "          \n",
    "          # Extraer campos de URL si existe\n",
    "          if hasattr(row, 'request') and row.request and row.request.url:\n",
    "            url_data = extract_url_fields(row.request.url)\n",
    "            record.update(url_data)\n",
    "          else:\n",
    "            # Si no hay URL, establecer todos los campos como None\n",
    "            record.update({field_name: None for field_name, _ in url_fields})\n",
    "          \n",
    "          parsed_logs.append(record)\n",
    "        except Exception as e:\n",
    "          conflicting_logs[i] = {\n",
    "            'error': str(e),\n",
    "            'line_content': all_lines[i-1].strip() if i <= len(all_lines) else \"no disponible\"\n",
    "          }\n",
    "  \n",
    "  for warning in w:\n",
    "    if issubclass(warning.category, ApacheWarning):\n",
    "      msg = str(warning.message)\n",
    "      match = re.search(r'Line (\\d+):', msg)\n",
    "      if match:\n",
    "        line_num = int(match.group(1))\n",
    "        if line_num <= len(all_lines):\n",
    "          problematic_logs[line_num] = {\n",
    "            'line_content': all_lines[line_num - 1].strip(),\n",
    "            'warning_message': msg,\n",
    "            'category': warning.category.__name__,\n",
    "          }\n",
    "\n",
    "total_problematic_logs = len(problematic_logs)\n",
    "total_conflicting_logs = len(conflicting_logs)\n",
    "total_parsed_logs = len(parsed_logs)\n",
    "total_logs = total_parsed_logs + total_problematic_logs + total_conflicting_logs\n",
    "\n",
    "print(f\"Total de logs procesados: {total_logs}\")\n",
    "print(f\"Problematic Logs: {total_problematic_logs} ({(total_problematic_logs / total_logs * 100 if total_logs != 0 else 0):.2f}%)\")\n",
    "print(f\"Conflicting Logs: {total_conflicting_logs} ({(total_conflicting_logs / total_logs * 100 if total_logs != 0 else 0):.2f}%)\")\n",
    "print(f\"Parsed Logs: {total_parsed_logs} ({(total_parsed_logs / total_logs * 100 if total_logs != 0 else 0):.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cadc00",
   "metadata": {},
   "source": [
    "**Problema**: Como son muchos datos, cargar los logs presentan una alta complejidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d051637",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsed = pd.DataFrame(parsed_logs)  \n",
    "display(df_parsed.head(5))\n",
    "display(df_parsed.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a95e888",
   "metadata": {},
   "source": [
    "### Análisis de Logs Problemáticos (`problematic_logs`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6ab945",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = max(problematic_logs.keys())\n",
    "\n",
    "logs = list(problematic_logs.items()) \n",
    "\n",
    "print(f\"Número Total de Logs: {len(problematic_logs.keys())}\")\n",
    "for log in logs:\n",
    "  idx = log[0]\n",
    "  line_content = log[1]['line_content']\n",
    "  print(f\"{idx:>{len(str(max_idx))}}) {line_content}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc635ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse import parse \n",
    "\n",
    "pattern = '{ip_client} {ident} {auth_user} [{timestamp}] {request_http} {status:d} {size:d} \"{referrer}\" \"{agent}\"'\n",
    "\n",
    "problematic_parsed_logs = []\n",
    "for problematic in list(problematic_logs.items()):\n",
    "  idx = problematic[0]\n",
    "  line_content = problematic[1]['line_content']\n",
    "  try: \n",
    "    parsed = parse(pattern, line_content.strip())\n",
    "    problematic_parsed_logs.append(parsed.named)\n",
    "  except Exception as e:\n",
    "    print(f\"Line {idx}: {line_content}\")\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "df_problematic = pd.DataFrame(problematic_parsed_logs)\n",
    "status_distribution = df_problematic['status'].value_counts().sort_index()\n",
    "display(df_problematic.shape[0])\n",
    "display(status_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b1b74f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
