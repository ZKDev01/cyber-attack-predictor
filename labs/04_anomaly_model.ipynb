{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b3a17b1",
   "metadata": {},
   "source": [
    "### Primer Modelo de Detección de Anomalías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b8c211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.model_selection import (\n",
    "  train_test_split,\n",
    "  cross_val_score,\n",
    "  GridSearchCV\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "  StandardScaler,\n",
    "  RobustScaler\n",
    ")\n",
    "from sklearn.ensemble import (\n",
    "  RandomForestClassifier, \n",
    "  IsolationForest\n",
    ")\n",
    "from sklearn.linear_model import (\n",
    "  LogisticRegression\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "  classification_report, \n",
    "  confusion_matrix,\n",
    "  roc_auc_score,\n",
    "  roc_curve,\n",
    "  precision_recall_curve,\n",
    "  f1_score,\n",
    "  recall_score, \n",
    "  precision_score\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Configuración de estilo para las gráficas\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "log_mlab_path = '../data/target/access_log_master_manual_labeling.csv'\n",
    "df = pd.read_csv(log_mlab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db9ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['anomaly'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e2d0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled = df[df['anomaly'] != -1]\n",
    "display(df_labeled['anomaly'].value_counts())\n",
    "display(df_labeled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0308af57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad66047",
   "metadata": {},
   "source": [
    "### Codificar Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a10f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing._label import LabelEncoder\n",
    "\n",
    "method_series = df_labeled['method'].copy()\n",
    "method_series = method_series.fillna('UNKNOWN')\n",
    "method_encoder = LabelEncoder()\n",
    "df_labeled['method_encoded'] = method_encoder.fit_transform(method_series)\n",
    "\n",
    "category_mapping = dict(zip(method_encoder.classes_, method_encoder.transform(method_encoder.classes_)))\n",
    "display(category_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38742901",
   "metadata": {},
   "source": [
    "### Training-Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ea2071",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "  #'ip_client', 'timestamp', 'status', \n",
    "  'size', \n",
    "  #'user_agent', \n",
    "  #'method',\n",
    "  'method_encoded',\n",
    "  #'url', \n",
    "  #'protocol', \n",
    "  #'anomaly', # target \n",
    "  #'status_category', \n",
    "  'url__count_sql_words','url__count_xss_words', 'url__count_command_words',\n",
    "  'url__count_auth_words', 'url__count_error_words',\n",
    "  'url__count_malware_words', 'url__count_danger_characters',\n",
    "  'url__count_obfuscation_code_words', 'url__count_dir_words',\n",
    "  'url__count_dot', 'url__count_http', 'url__count_percentage_symbol',\n",
    "  'url__count_question_symbol', 'url__count_hyphen', 'url__count_equal',\n",
    "  'url__url_length', 'url__digit_count', 'url__letter_count',\n",
    "  'url__count_special_characters', 'url__is_encoded',\n",
    "  'url__unusual_character_ratio'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ca8f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_labeled[features]\n",
    "y = df_labeled['anomaly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f878a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e153d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 5, figsize=(20, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(features):\n",
    "  for label in [0, 1]:\n",
    "    subset = X[y == label][feature]\n",
    "    if subset.dtype == bool:\n",
    "      subset = subset.astype(int)\n",
    "    axes[idx].hist(subset, alpha=0.5, label=f'Class {label}', bins=30)\n",
    "  axes[idx].set_title(feature)\n",
    "  axes[idx].legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3415e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = pd.concat([X, y], axis=1).corr()['anomaly'].sort_values(ascending=False)\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8c31d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X, y,\n",
    "  test_size=0.2,\n",
    "  random_state=42,\n",
    "  stratify=y  # Importante para datos desbalanceados\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98df5240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar RobustScaler por si hay outliers\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convertir de nuevo a DataFrame para mejor visualización\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=features, index=X_train.index)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=features, index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc16ee83",
   "metadata": {},
   "source": [
    "### Baseline: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8ffd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_base = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    class_weight='balanced',  # Ajusta pesos automáticamente\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_base.fit(X_train_scaled_df, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_rf = rf_base.predict(X_test_scaled_df)\n",
    "y_pred_proba_rf = rf_base.predict_proba(X_test_scaled_df)[:, 1]\n",
    "\n",
    "# Métricas\n",
    "print(\"=== Random Forest Base ===\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_rf):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"Recall (detección de anomalías): {recall_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_rf):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['Normal', 'Anomalía']))\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Anomalía'], yticklabels=['Normal', 'Anomalía'])\n",
    "plt.title('Matriz de Confusión - Random Forest')\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Predicho')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ef3180",
   "metadata": {},
   "source": [
    "### Modelo con SMOTE (Oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d701c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_pipeline = ImbPipeline([\n",
    "    ('smote', SMOTE(random_state=42, sampling_strategy=0.5)),  # Reducir desbalanceo\n",
    "    ('classifier', RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "smote_pipeline.fit(X_train_scaled_df, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_smote = smote_pipeline.predict(X_test_scaled_df)\n",
    "y_pred_proba_smote = smote_pipeline.predict_proba(X_test_scaled_df)[:, 1]\n",
    "\n",
    "print(\"=== Random Forest con SMOTE ===\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_smote):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_smote):.4f}\")\n",
    "print(f\"Recall (detección de anomalías): {recall_score(y_test, y_pred_smote):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_smote):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_smote, target_names=['Normal', 'Anomalía']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435429fb",
   "metadata": {},
   "source": [
    "### XGBoost con Manejo de Desbalanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610dad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular ratio de desbalanceo para XGBoost\n",
    "scale_pos_weight = len(y_train[y_train==0]) / len(y_train[y_train==1])  # normal/anomaly\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=scale_pos_weight,  # Manejo de clases desbalanceadas\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train_scaled_df, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_xgb = xgb_model.predict(X_test_scaled_df)\n",
    "y_pred_proba_xgb = xgb_model.predict_proba(X_test_scaled_df)[:, 1]\n",
    "\n",
    "print(\"=== XGBoost ===\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_xgb):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(f\"Recall (detección de anomalías): {recall_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb, target_names=['Normal', 'Anomalía']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17ac3a3",
   "metadata": {},
   "source": [
    "### Comparación de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b9d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar curvas ROC\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Random Forest Base\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_proba_rf)\n",
    "auc_rf = roc_auc_score(y_test, y_pred_proba_rf)\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {auc_rf:.3f})', linewidth=2)\n",
    "\n",
    "# Random Forest con SMOTE\n",
    "fpr_smote, tpr_smote, _ = roc_curve(y_test, y_pred_proba_smote)\n",
    "auc_smote = roc_auc_score(y_test, y_pred_proba_smote)\n",
    "plt.plot(fpr_smote, tpr_smote, label=f'Random Forest + SMOTE (AUC = {auc_smote:.3f})', linewidth=2)\n",
    "\n",
    "# XGBoost\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_pred_proba_xgb)\n",
    "auc_xgb = roc_auc_score(y_test, y_pred_proba_xgb)\n",
    "plt.plot(fpr_xgb, tpr_xgb, label=f'XGBoost (AUC = {auc_xgb:.3f})', linewidth=2)\n",
    "\n",
    "# Línea de referencia\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Clasificador Aleatorio')\n",
    "\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curvas ROC - Comparación de Modelos')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f895cb16",
   "metadata": {},
   "source": [
    "### Validación Cruzada Estratificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f19cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar importaciones necesarias\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_fscore_support\n",
    "\n",
    "# Definir las métricas de evaluación\n",
    "def evaluate_model(model, X, y, cv=5):\n",
    "    \"\"\"\n",
    "    Evalúa un modelo usando validación cruzada estratificada y devuelve métricas.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo de sklearn con .fit() y .predict_proba()\n",
    "        X: Características\n",
    "        y: Etiquetas\n",
    "        cv: Número de folds (por defecto 5)\n",
    "    \n",
    "    Returns:\n",
    "        Diccionario con métricas promedio\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Almacenar métricas por fold\n",
    "    accuracies, aucs, precisions, recalls, f1_scores = [], [], [], [], []\n",
    "    \n",
    "    # Predicciones para métricas globales\n",
    "    y_true_all = []\n",
    "    y_pred_all = []\n",
    "    y_pred_proba_all = []\n",
    "    \n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Aplicar SMOTE solo en el fold de entrenamiento\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "        \n",
    "        # Entrenar modelo\n",
    "        model.fit(X_train_res, y_train_res)\n",
    "        \n",
    "        # Predecir\n",
    "        y_pred = model.predict(X_val)\n",
    "        y_pred_proba = model.predict_proba(X_val)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "        \n",
    "        # Calcular métricas\n",
    "        accuracies.append(accuracy_score(y_val, y_pred))\n",
    "        if y_pred_proba is not None:\n",
    "            aucs.append(roc_auc_score(y_val, y_pred_proba))\n",
    "        \n",
    "        # Métricas por clase (para anomalía=1)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            y_val, y_pred, average='binary', pos_label=1, zero_division=0\n",
    "        )\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        # Acumular para métricas globales\n",
    "        y_true_all.extend(y_val)\n",
    "        y_pred_all.extend(y_pred)\n",
    "        if y_pred_proba is not None:\n",
    "            y_pred_proba_all.extend(y_pred_proba)\n",
    "    \n",
    "    # Métricas promedio\n",
    "    metrics = {\n",
    "        'accuracy_mean': np.mean(accuracies),\n",
    "        'accuracy_std': np.std(accuracies),\n",
    "        'auc_mean': np.mean(aucs) if aucs else None,\n",
    "        'auc_std': np.std(aucs) if aucs else None,\n",
    "        'precision_mean': np.mean(precisions),\n",
    "        'precision_std': np.std(precisions),\n",
    "        'recall_mean': np.mean(recalls),\n",
    "        'recall_std': np.std(recalls),\n",
    "        'f1_mean': np.mean(f1_scores),\n",
    "        'f1_std': np.std(f1_scores),\n",
    "    }\n",
    "    \n",
    "    # Métricas globales\n",
    "    global_metrics = {\n",
    "        'global_accuracy': accuracy_score(y_true_all, y_pred_all),\n",
    "        'global_auc': roc_auc_score(y_true_all, y_pred_proba_all) if y_pred_proba_all else None,\n",
    "        'global_precision': precision_recall_fscore_support(\n",
    "            y_true_all, y_pred_all, average='binary', pos_label=1, zero_division=0\n",
    "        )[0],\n",
    "        'global_recall': precision_recall_fscore_support(\n",
    "            y_true_all, y_pred_all, average='binary', pos_label=1, zero_division=0\n",
    "        )[1],\n",
    "        'global_f1': precision_recall_fscore_support(\n",
    "            y_true_all, y_pred_all, average='binary', pos_label=1, zero_division=0\n",
    "        )[2],\n",
    "    }\n",
    "    \n",
    "    return metrics, global_metrics\n",
    "\n",
    "# Evaluar múltiples modelos\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "    'XGBoost': XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nEvaluando {name}...\")\n",
    "    metrics, global_metrics = evaluate_model(model, X, y, cv=5)\n",
    "    results[name] = {\n",
    "        'cv_metrics': metrics,\n",
    "        'global_metrics': global_metrics\n",
    "    }\n",
    "    \n",
    "    # Imprimir resultados\n",
    "    print(f\"  Validación Cruzada (promedio ± std):\")\n",
    "    print(f\"    Accuracy:  {metrics['accuracy_mean']:.4f} ± {metrics['accuracy_std']:.4f}\")\n",
    "    if metrics['auc_mean']:\n",
    "        print(f\"    AUC:       {metrics['auc_mean']:.4f} ± {metrics['auc_std']:.4f}\")\n",
    "    print(f\"    Precision: {metrics['precision_mean']:.4f} ± {metrics['precision_std']:.4f}\")\n",
    "    print(f\"    Recall:    {metrics['recall_mean']:.4f} ± {metrics['recall_std']:.4f}\")\n",
    "    print(f\"    F1:        {metrics['f1_mean']:.4f} ± {metrics['f1_std']:.4f}\")\n",
    "    \n",
    "    print(f\"  Métricas Globales (en todos los datos):\")\n",
    "    print(f\"    Accuracy:  {global_metrics['global_accuracy']:.4f}\")\n",
    "    if global_metrics['global_auc']:\n",
    "        print(f\"    AUC:       {global_metrics['global_auc']:.4f}\")\n",
    "    print(f\"    Precision: {global_metrics['global_precision']:.4f}\")\n",
    "    print(f\"    Recall:    {global_metrics['global_recall']:.4f}\")\n",
    "    print(f\"    F1:        {global_metrics['global_f1']:.4f}\")\n",
    "\n",
    "# Opcional: Graficar comparación de modelos\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "metrics_to_plot = ['accuracy', 'auc', 'precision', 'recall', 'f1']\n",
    "\n",
    "for idx, metric in enumerate(metrics_to_plot):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    model_names = list(results.keys())\n",
    "    means = [results[name]['cv_metrics'][f'{metric}_mean'] for name in model_names]\n",
    "    stds = [results[name]['cv_metrics'][f'{metric}_std'] for name in model_names]\n",
    "    \n",
    "    ax.bar(model_names, means, yerr=stds, capsize=5, alpha=0.7)\n",
    "    ax.set_title(f'{metric.capitalize()} (CV)')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6acb16",
   "metadata": {},
   "source": [
    "### Optimización de Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d33707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimización para Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'class_weight': ['balanced', {0: 1, 1: 3}]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "grid_search = GridSearchCV(\n",
    "    rf, \n",
    "    param_grid, \n",
    "    cv=3,  # Usar menos folds por tiempo\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled_df, y_train)\n",
    "\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor F1-Score:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluar el mejor modelo\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_best = best_rf.predict(X_test_scaled_df)\n",
    "print(\"\\n=== Mejor Random Forest ===\")\n",
    "print(classification_report(y_test, y_pred_best, target_names=['Normal', 'Anomalía']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a102f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener importancia de características del mejor modelo\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': best_rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=feature_importance.head(15), x='importance', y='feature')\n",
    "plt.title('Top 15 Características Más Importantes')\n",
    "plt.xlabel('Importancia')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 10 características más importantes:\")\n",
    "print(feature_importance.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
