{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377ff121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import math \n",
    "#import eli5\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import sklearn \n",
    "#from eli5.sklearn import PermutationImportance\n",
    "from urllib.parse import urlparse \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#import tensorflow as tf\n",
    "#from tensorflow.keras import layers\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "#from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "#from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "#import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4ceca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/test_dataset/CSIC2010/csic_database.csv'\n",
    "df = pd.read_csv(PATH)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12daaf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of samples: {df.shape[0]}\")\n",
    "print(f\"Number of features: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5284c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bdc9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3ec582",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "sns.countplot(data=df, x='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2ca039",
   "metadata": {},
   "source": [
    "Dropping samples with at least 1 NaN value will make to lose all the other Request Methods besides POST, this option is discarded since dropping data is not usually a good choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f6ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = df.columns\n",
    "print(feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811b9a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_features = [\n",
    "  'Unnamed: 0', \n",
    "  'Method', \n",
    "  'User-Agent', \n",
    "  'Pragma', \n",
    "  'Cache-Control',\n",
    "  'Accept', \n",
    "  'Accept-encoding', \n",
    "  'Accept-charset', \n",
    "  'language', \n",
    "  'host',\n",
    "  'cookie', \n",
    "  'content-type', \n",
    "  'connection', \n",
    "  'lenght', \n",
    "  'content',\n",
    "  'classification', \n",
    "  'URL'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b20b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[total_features]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6102d8d4",
   "metadata": {},
   "source": [
    "#### Removing not discriminatory features\n",
    "Enumerating unique values for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89e35ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing not discriminatory features and making some adjustments on feature names\n",
    "X = X.rename(columns={'Unnamed: 0': 'Class'})\n",
    "X = X.rename(columns={'lenght': 'content_length'})\n",
    "\n",
    "feature_names = [\n",
    "  'Class',\n",
    "  'Method',\n",
    "  'host',\n",
    "  'cookie',\n",
    "  'Accept', \n",
    "  'content_length', \n",
    "  'content',\n",
    "  'classification',\n",
    "  'URL'\n",
    "]\n",
    "X = X[feature_names]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f582344",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=X.Class\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4e662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = X.shape[1]\n",
    "# Get list of categorical variables\n",
    "s = (X.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "print(f\"Categorical variables: {object_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c34a79",
   "metadata": {},
   "source": [
    "Load Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fee98f6",
   "metadata": {},
   "source": [
    "#### Pre-Processing on the feature: Content Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8df439",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.content_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2252b710",
   "metadata": {},
   "source": [
    "Operations on the 'content_lenght' feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd43979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN values with 0\n",
    "# removing the 'content-lenght' string and keeping only the numerical value \n",
    "X['content_length'] = X['content_length'].astype(str)\n",
    "X['content_length'] = X['content_length'].str.extract(r'(\\d+)')\n",
    "X['content_length'] = pd.to_numeric(X['content_length'], errors='coerce').fillna(0)\n",
    "print(X.content_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10a14b4",
   "metadata": {},
   "source": [
    "GET methods have the content_length set to 0 since they where all NaN (this method does not have to provide content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034925ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_length = X.loc[X['Method'] == 'GET', 'content_length']\n",
    "print(filtered_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b0617c",
   "metadata": {},
   "source": [
    "URL PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32460da",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_counts = X['URL'].value_counts()\n",
    "most_common_urls = url_counts.head(10)  # Extract the top 10 most common strings\n",
    "\n",
    "print(\"Most common URLs:\")\n",
    "for i, (url, count) in enumerate(most_common_urls.items(), 1):\n",
    "  print(f\"{i}. URL: {url} - Count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cf878a",
   "metadata": {},
   "source": [
    "Utils for URL/Content pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2c9c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_dot(url):\n",
    "  count_dot = url.count('.')\n",
    "  return count_dot\n",
    "\n",
    "def no_of_dir(url):\n",
    "  urldir = urlparse(url).path\n",
    "  return urldir.count('/')\n",
    "\n",
    "def no_of_embed(url):\n",
    "  urldir = urlparse(url).path\n",
    "  return urldir.count('//')\n",
    "\n",
    "def shortening_service(url):\n",
    "  match = re.search('bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n",
    "                    'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n",
    "                    'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n",
    "                    'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n",
    "                    'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n",
    "                    'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n",
    "                    'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|'\n",
    "                    'tr\\.im|link\\.zip\\.net',\n",
    "                    url)\n",
    "  if match:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "def count_http(url):\n",
    "  return url.count('http')\n",
    "\n",
    "def count_per(url):\n",
    "  return url.count('%')\n",
    "\n",
    "def count_ques(url):\n",
    "  return url.count('?')\n",
    "\n",
    "def count_hyphen(url):\n",
    "  return url.count('-')\n",
    "\n",
    "def count_equal(url):\n",
    "  return url.count('=')\n",
    "\n",
    "def url_length(url):\n",
    "  return len(str(url))\n",
    "\n",
    "#Hostname Length\n",
    "def hostname_length(url):\n",
    "  return len(urlparse(url).netloc)\n",
    "\n",
    "import re\n",
    "\n",
    "def suspicious_words(url):\n",
    "  score_map = {\n",
    "    'error': 30,\n",
    "    'errorMsg': 30,\n",
    "    'id': 10,\n",
    "    'errorID': 30,\n",
    "    'SELECT': 50,\n",
    "    'FROM': 50,\n",
    "    'WHERE': 50,\n",
    "    'DELETE': 50,\n",
    "    'USERS': 50,\n",
    "    'DROP': 50,\n",
    "    'CREATE': 50,\n",
    "    'INJECTED': 50,\n",
    "    'TABLE': 50,\n",
    "    'alert': 30,\n",
    "    'javascript': 20,\n",
    "    'cookie': 25,\n",
    "    '--': 30,\n",
    "    '.exe': 30,\n",
    "    '.php': 20,\n",
    "    '.js': 10,\n",
    "    'admin': 10,\n",
    "    'administrator': 10,\n",
    "    '\\'': 30,\n",
    "    'password': 15,\n",
    "    'login': 15,\n",
    "    'incorrect': 20,\n",
    "    'pwd': 15,\n",
    "    'tamper': 25,\n",
    "    'vaciar': 20,\n",
    "    'carrito': 25,\n",
    "    'wait': 30,\n",
    "    'delay': 35,\n",
    "    'set': 20,\n",
    "    'steal': 35,\n",
    "    'hacker': 35,\n",
    "    'proxy': 35,\n",
    "    'location': 30,\n",
    "    'document.cookie': 40,\n",
    "    'document': 20,\n",
    "    'set-cookie': 40,\n",
    "    'create': 40,\n",
    "    'cmd': 40,\n",
    "    'dir': 30,\n",
    "    'shell': 40,\n",
    "    'reverse': 30,\n",
    "    'bin': 20,\n",
    "    'cookiesteal': 40,\n",
    "    'LIKE': 30,\n",
    "    'UNION': 35,\n",
    "    'include': 30,\n",
    "    'file': 20,\n",
    "    'tmp': 25,\n",
    "    'ssh': 40,\n",
    "    'exec': 30,\n",
    "    'cat': 25,\n",
    "    'etc': 30,\n",
    "    'fetch': 25,\n",
    "    'eval': 30,\n",
    "    'wait': 30,\n",
    "    'malware': 45,\n",
    "    'ransomware': 45,\n",
    "    'phishing': 45,\n",
    "    'exploit': 45,\n",
    "    'virus': 45,\n",
    "    'trojan': 45,\n",
    "    'backdoor': 45,\n",
    "    'spyware': 45,\n",
    "    'rootkit': 45,\n",
    "    'credential': 30,\n",
    "    'inject': 30,\n",
    "    'script': 25,\n",
    "    'iframe': 25,\n",
    "    'src=': 25,\n",
    "    'onerror': 30,\n",
    "    'prompt': 20,\n",
    "    'confirm': 20,\n",
    "    'eval': 25,\n",
    "    'expression': 30,\n",
    "    'function\\(': 20,\n",
    "    'xmlhttprequest': 30,\n",
    "    'xhr': 20,\n",
    "    'window.': 20,\n",
    "    'document.': 20,\n",
    "    'cookie': 25,\n",
    "    'click': 15,\n",
    "    'mouseover': 15,\n",
    "    'onload': 20,\n",
    "    'onunload': 20,\n",
    "  }\n",
    "\n",
    "  matches = re.findall(r'(?i)' + '|'.join(score_map.keys()), url)\n",
    "\n",
    "  total_score = sum(score_map.get(match.lower(), 0) for match in matches)\n",
    "  return total_score\n",
    "\n",
    "def digit_count(url):\n",
    "  digits = 0\n",
    "  for i in url:\n",
    "    if i.isnumeric():\n",
    "      digits = digits + 1\n",
    "  return digits\n",
    "\n",
    "def letter_count(url):\n",
    "  letters = 0\n",
    "  for i in url:\n",
    "    if i.isalpha():\n",
    "      letters += 1\n",
    "  return letters\n",
    "\n",
    "def count_special_characters(url):\n",
    "  special_characters = re.sub(r'[a-zA-Z0-9\\s]', '', url)\n",
    "  count = len(special_characters)\n",
    "  return count\n",
    "\n",
    "# Number of Parameters in URL\n",
    "def number_of_parameters(url):\n",
    "  params = urlparse(url).query\n",
    "  return 0 if params == '' else len(params.split('&'))\n",
    "\n",
    "# Number of Fragments in URL\n",
    "def number_of_fragments(url):\n",
    "  frags = urlparse(url).fragment\n",
    "  return len(frags.split('#')) - 1 if frags == '' else 0\n",
    "\n",
    "# URL is Encoded\n",
    "def is_encoded(url):\n",
    "  return int('%' in url.lower())\n",
    "\n",
    "def unusual_character_ratio(url):\n",
    "  total_characters = len(url)\n",
    "  unusual_characters = re.sub(r'[a-zA-Z0-9\\s\\-._]', '', url)\n",
    "  unusual_count = len(unusual_characters)\n",
    "  ratio = unusual_count / total_characters if total_characters > 0 else 0\n",
    "  return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e4d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['count_dot_url'] = X['URL'].apply(count_dot)\n",
    "X['count_dir_url'] = X['URL'].apply(no_of_dir)\n",
    "X['count_embed_domain_url'] = X['URL'].apply(no_of_embed)\n",
    "X['short_url'] = X['URL'].apply(shortening_service)\n",
    "X['count-http'] = X['URL'].apply(count_http)\n",
    "X['count%_url'] = X['URL'].apply(count_per)\n",
    "X['count?_url'] = X['URL'].apply(count_ques)\n",
    "X['count-_url'] = X['URL'].apply(count_hyphen)\n",
    "X['count=_url'] = X['URL'].apply(count_equal)\n",
    "X['hostname_length_url'] = X['URL'].apply(hostname_length)\n",
    "X['sus_url'] = X['URL'].apply(suspicious_words)\n",
    "X['count-digits_url'] = X['URL'].apply(digit_count)\n",
    "X['count-letters_url'] = X['URL'].apply(letter_count)\n",
    "X['url_length'] = X['URL'].apply(url_length)\n",
    "X['number_of_parameters_url'] = X['URL'].apply(number_of_parameters)\n",
    "X['number_of_fragments_url'] = X['URL'].apply(number_of_fragments)\n",
    "X['is_encoded_url'] = X['URL'].apply(is_encoded)\n",
    "X['special_count_url'] = X['URL'].apply(count_special_characters)\n",
    "X['unusual_character_ratio_url'] = X['URL'].apply(unusual_character_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc95955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features and class variable for plotting\n",
    "new_features = ['count_dot_url', 'count_dir_url', 'count_embed_domain_url', 'count-http',\n",
    "                'count%_url', 'count?_url', 'count-_url', 'count=_url', 'url_length', 'hostname_length_url',\n",
    "                'sus_url', 'count-digits_url', 'count-letters_url', 'number_of_parameters_url',\n",
    "                'number_of_fragments_url', 'is_encoded_url','special_count_url','unusual_character_ratio_url']\n",
    "\n",
    "# Create a DataFrame with the selected features\n",
    "set = X[new_features]\n",
    "\n",
    "for new_feature in X.columns:\n",
    "  if new_feature in X.columns:\n",
    "    unique_count = X[new_feature].nunique()\n",
    "    print(f\"Number of unique values for {new_feature}: {unique_count}\")\n",
    "  else:\n",
    "    print(f\"Column '{new_feature}' does not exist in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de97f446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Cookies as Feature \n",
    "## cookies are unique for each sample, this feature cannot be used as discriminant \n",
    "unique_count = X['cookie'].nunique()\n",
    "print(f\"Count of unique values in 'cookie': {unique_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14b5d70",
   "metadata": {},
   "source": [
    "#### Encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a09986",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Accept'] = X['Accept'].astype(str)\n",
    "X['Accept'] = X['Accept'].str.extract(r'(\\d+)')\n",
    "X['Accept'] = pd.to_numeric(X['Accept'], errors='coerce').fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f77ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_make = LabelEncoder()\n",
    "X[\"Method_enc\"] = lb_make.fit_transform(X[\"Method\"])\n",
    "X[\"host_enc\"] =lb_make.fit_transform(X[\"host\"])\n",
    "X[\"Accept_enc\"] =lb_make.fit_transform(X[\"Accept\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec8b760",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count_met = X[\"Method_enc\"].nunique()\n",
    "unique_count_host = X[\"host_enc\"].nunique()\n",
    "unique_count_acc = X[\"Accept_enc\"].nunique()\n",
    "\n",
    "\n",
    "print(f\"Number of unique values for 'Method_enc': {unique_count_met}\")\n",
    "print(f\"Number of unique values for 'host_enc': {unique_count_host}\")\n",
    "print(f\"Number of unique values for 'Accept_enc': {unique_count_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49fda62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c62436",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc77e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_to_content(content,function):\n",
    "  if pd.isna(content):\n",
    "    return 0\n",
    "  elif isinstance(content, str):\n",
    "    return function(content)\n",
    "\n",
    "#\"\"\"\n",
    "#                'count_dot_content','count_dir_content','count_embed_domain_content','count%_content','count?_content',\n",
    "#               'count-_content','count=_content','hostname_length_content','sus_content','count_digits_content',\n",
    "#              'count_letters_content','content_length','number_of_parameters_content','number_of_fragments_content',\n",
    "#             'is_encoded_content','special_count_content','unusual_character_ratio_content'\n",
    "#            ]\"\"\"\n",
    "\n",
    "X['count_dot_content'] = X['content'].apply(apply_to_content, function=count_dot)\n",
    "X['count_dir_content'] = X['content'].apply(apply_to_content, function=no_of_dir)\n",
    "X['count_embed_domain_content'] = X['content'].apply(apply_to_content, function=no_of_embed)\n",
    "X['count%_content'] = X['content'].apply(apply_to_content, function=count_per)\n",
    "X['count?_content'] = X['content'].apply(apply_to_content, function=count_ques)\n",
    "X['count-_content'] = X['content'].apply(apply_to_content, function=count_hyphen)\n",
    "X['count=_content'] = X['content'].apply(apply_to_content, function=count_equal)\n",
    "X['content_length'] = X['content'].apply(apply_to_content, function=url_length)\n",
    "X['sus_content'] = X['content'].apply(apply_to_content, function=suspicious_words)\n",
    "X['count_digits_content'] = X['content'].apply(apply_to_content, function=digit_count)\n",
    "X['count_letters_content'] = X['content'].apply(apply_to_content, function=letter_count)\n",
    "X['special_count_content'] = X['content'].apply(apply_to_content, function=count_special_characters)\n",
    "X['is_encoded_content'] = X['content'].apply(apply_to_content, function=is_encoded)\n",
    "#X['unusual_character_ratio_content'] = X['content'].apply(apply_to_content, function=unusual_character_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e809674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select the features and class variable for plotting\n",
    "new_content_features = [\n",
    "  'count_dot_content', 'count_dir_content', \n",
    "  'count_embed_domain_content', 'count%_content', \n",
    "  'count?_content', 'count-_content', \n",
    "  'count=_content', 'sus_content', \n",
    "  'count_digits_content', 'count_letters_content', \n",
    "  'content_length', 'is_encoded_content', \n",
    "  'special_count_content'\n",
    "]\n",
    "\n",
    "# Create a DataFrame with the selected features\n",
    "selected_features_df = X[new_content_features]\n",
    "\n",
    "for feature_name in selected_features_df.columns:\n",
    "  if feature_name in X.columns:\n",
    "    unique_count = selected_features_df[feature_name].nunique()\n",
    "    print(f\"Number of unique values for {feature_name}: {unique_count}\")\n",
    "  else:\n",
    "    print(f\"Column '{feature_name}' does not exist in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27e8e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c005aa86",
   "metadata": {},
   "source": [
    "#### Building the final dataset to use for the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717be7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf28954",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['count_dot_url', 'count_dir_url', 'count_embed_domain_url', 'count-http',\n",
    "        'count%_url', 'count?_url', 'count-_url', 'count=_url', 'url_length', 'hostname_length_url',\n",
    "        'sus_url', 'count-digits_url', 'count-letters_url', 'number_of_parameters_url',\n",
    "        'is_encoded_url','special_count_url','unusual_character_ratio_url',\n",
    "        #method\n",
    "        'Method_enc',\n",
    "        #content\n",
    "        'count_dot_content','count%_content',\n",
    "        'count-_content','count=_content','sus_content','count_digits_content',\n",
    "        'count_letters_content','content_length',\n",
    "        'is_encoded_content','special_count_content']\n",
    "print(X[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e9dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=X['classification']\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4be541",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('computing...)')\n",
    "#split dataset in test and train \n",
    "x_tr, x_ts, y_tr, y_ts = train_test_split(X[labels], y, test_size=0.3, random_state=0)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a2bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdbe659",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr.tail(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc67a1cc",
   "metadata": {},
   "source": [
    "#### Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1851bdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model = RandomForestClassifier(random_state=1000)\n",
    "print('Computing....')\n",
    "# Fit the model\n",
    "random_forest_model.fit(x_tr,y_tr)\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4973e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "selector = SelectFromModel(random_forest_model, threshold=\"mean\")\n",
    "X_train_selected = selector.transform(x_tr)\n",
    "X_test_selected = selector.transform(x_ts)\n",
    "\n",
    "svm = SVC(kernel='rbf', C=2, gamma='scale')  # You can tune these hyperparameters\n",
    "svm.fit(X_train_selected, y_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c9b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm.predict(X_test_selected)\n",
    "accuracy = accuracy_score(y_ts, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_ts, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce7d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "RT_predictions= random_forest_model.predict(x_ts)\n",
    "print('MAE', mean_absolute_error(y_ts, RT_predictions))\n",
    "print(\"Accuracy\", accuracy_score(y_ts, RT_predictions))\n",
    "print(\"Precision\", precision_score(y_ts, RT_predictions, average='weighted', labels=np.unique(RT_predictions)))\n",
    "print(\"Recall\", recall_score(y_ts, RT_predictions, average='weighted', labels=np.unique(RT_predictions)))\n",
    "print(\"F1\", f1_score(y_ts, RT_predictions, average='weighted', labels=np.unique(RT_predictions)))\n",
    "print(\"ROC AUC\", roc_auc_score(y_ts, RT_predictions, average='weighted', labels=np.unique(RT_predictions)))\n",
    "error_rt = (RT_predictions != y_ts).mean()\n",
    "print(\"Test error: {:.1%}\".format(error_rt))\n",
    "\n",
    "\n",
    "# save the model \n",
    "filename = 'APPLICATION LAYER.sav'\n",
    "joblib.dump(random_forest_model, open(filename, 'wb')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b4576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_tr.unique())\n",
    "print(y_tr.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb10306",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ts = x_ts.reset_index(drop=True)\n",
    "y_ts = y_ts.reset_index(drop=True)\n",
    "\n",
    "for k in range(np.unique(y_ts).size):\n",
    "  print('mean of class ' + str(k) + ':\\n', x_ts[y_ts == k].mean(axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1afff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_ts, RT_predictions, target_names = ['Normal (class 0)','Anomalous (class 1)']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8266e858",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['Normal', 'Anomalous']\n",
    "cm = confusion_matrix(y_ts, RT_predictions)\n",
    "cm = pd.DataFrame(cm, index=['0', '1'], columns=['0', '1'])\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cm, cmap=\"Blues\", linecolor='black', linewidth=1, annot=True, fmt='', xticklabels=label, yticklabels=label)\n",
    "plt.title(\"Random Forest\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f832e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_model = DecisionTreeClassifier(random_state=2)\n",
    "print('Computing....')\n",
    "DT_model.fit(x_tr,y_tr)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb88ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_predictions= DT_model.predict(x_ts)\n",
    "print('MAE', mean_absolute_error(y_ts, DT_predictions))\n",
    "print(\"Accuracy\", accuracy_score(y_ts, DT_predictions))\n",
    "print(\"Precision\", precision_score(y_ts, DT_predictions, average='weighted', labels=np.unique(DT_predictions)))\n",
    "print(\"Recall\", recall_score(y_ts, DT_predictions, average='weighted', labels=np.unique(DT_predictions)))\n",
    "print(\"F1\", f1_score(y_ts, DT_predictions, average='weighted', labels=np.unique(DT_predictions)))\n",
    "print(\"ROC AUC\", roc_auc_score(y_ts, DT_predictions, average='weighted', labels=np.unique(DT_predictions)))\n",
    "error_dt = (DT_predictions != y_ts).mean()\n",
    "print(\"Test error: {:.1%}\".format(error_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e99db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_ts,DT_predictions)\n",
    "cm = pd.DataFrame(cm , index = ['0','1'] , columns = ['0','1'])\n",
    "plt.title(\"Decision Tree\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "sns.heatmap(cm,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='',xticklabels = label,yticklabels = label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
