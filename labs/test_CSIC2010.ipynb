{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377ff121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import math \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from typing import List, Callable \n",
    "\n",
    "from parse import parse \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import  SelectFromModel\n",
    "from sklearn.model_selection import (\n",
    "  StratifiedKFold,\n",
    "  train_test_split,\n",
    "  GridSearchCV\n",
    ")\n",
    "from sklearn.ensemble import (\n",
    "  RandomForestClassifier, \n",
    ")\n",
    "from sklearn.metrics import (\n",
    "  precision_score,\n",
    "  accuracy_score,\n",
    "  recall_score, \n",
    "  f1_score, \n",
    "  roc_auc_score, \n",
    "  mean_absolute_error,\n",
    "  confusion_matrix, \n",
    "  classification_report\n",
    ")\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import (\n",
    "  LinearSVC,\n",
    "  SVC\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "log_prep_path = '../data/test_dataset/CSIC2010/csic_database.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4ceca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(log_prep_path)\n",
    "df = df.rename(columns={'Unnamed: 0': 'Class'})\n",
    "df = df.rename(columns={'lenght': 'content_length'})\n",
    "\n",
    "# Eliminar protocolo ( http:// o https:// ) y el host de la URL\n",
    "df['URL'] = df['URL'].str.replace(r'^https?://', '', regex=True)\n",
    "df['URL'] = df.apply(lambda row : row['URL'].replace(row['host'], '', 1), axis=1)\n",
    "\n",
    "def parse_url(row):\n",
    "  pattern = '{request_url} {protocol}'  \n",
    "  result = parse(pattern, row['URL'])\n",
    "  \n",
    "  if result:\n",
    "    return pd.Series( [result['request_url'], result['protocol']] )\n",
    "  else: # Fallback si no coincide\n",
    "    raise Exception(f\"Error in URL: {row['URL']}\")\n",
    "\n",
    "df[['request_url', 'protocol']] = df.apply(parse_url, axis=1)\n",
    "\n",
    "del_columns = [\n",
    "  'Pragma',\n",
    "  'Cache-Control',\n",
    "  'Accept',\n",
    "  'Accept-encoding',\n",
    "  'Accept-charset',\n",
    "  'language',\n",
    "  'host',\n",
    "  'cookie',\n",
    "  'content-type',\n",
    "  'connection',       \n",
    "  'classification',   # Es la variable categórica ya codificada de la columna Class\n",
    "  'content_length',   # Eliminar del dataset debido a problemas entre el valor original y el valor de la columna de request_url\n",
    "  'URL'               # Ya esta separado URL en request_url y protocol\n",
    "]\n",
    "df_selected = df.drop(columns=del_columns, axis=1)\n",
    "\n",
    "display(df_selected.head())\n",
    "display(df_selected.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d610edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_columns = [\n",
    "  'Class',\n",
    "  'Method',\n",
    "  'User-Agent',\n",
    "  'protocol'\n",
    "]\n",
    "\n",
    "# Filtrar solo columnas existentes\n",
    "existing_cols = [col for col in important_columns if col in df_selected.columns]\n",
    "n_cols = len(existing_cols)\n",
    "\n",
    "# Configurar subplots\n",
    "fig, axes = plt.subplots(n_cols, 1, figsize=(15, 5 * n_cols))\n",
    "if n_cols == 1:\n",
    "  axes = [axes]\n",
    "\n",
    "# Crear gráficas para cada columna\n",
    "for idx, col in enumerate(existing_cols):\n",
    "  ax = axes[idx]\n",
    "  \n",
    "  # Obtener value counts (top 10 para evitar sobrecarga)\n",
    "  value_counts = df_selected[col].value_counts().head(10)\n",
    "  \n",
    "  # Para columnas con muchos valores únicos, mostrar solo top\n",
    "  if len(value_counts) > 10:\n",
    "    others_count = df_selected[col].value_counts().iloc[10:].sum()\n",
    "    if others_count > 0:\n",
    "      value_counts['Otros'] = others_count\n",
    "  \n",
    "  # Crear gráfica de barras horizontal\n",
    "  bars = ax.barh(range(len(value_counts)), value_counts.values, color=plt.cm.tab20c(range(len(value_counts))))\n",
    "  \n",
    "  ax.set_title(f'Distribución de {col}', fontsize=12, fontweight='bold')\n",
    "  ax.set_xlabel('Frecuencia', fontsize=10)\n",
    "  ax.set_yticks(range(len(value_counts)))\n",
    "  ax.set_yticklabels(value_counts.index, fontsize=9)\n",
    "  \n",
    "  # Añadir etiquetas de valores\n",
    "  total = value_counts.sum()\n",
    "  for i, v in enumerate(value_counts.values):\n",
    "    percentage = (v / total) * 100\n",
    "    ax.text(v + max(value_counts.values) * 0.01, i, f'{v} ({percentage:.1f}%)', va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f2640e",
   "metadata": {},
   "source": [
    "Este dataset en muy sencillo por lo que no hay muchos valores únicos por parte de columnas como `protocol` y `User-Agent` por lo que se opta por eliminar estas columnas del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07a21c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_columns = [\n",
    "  'protocol',\n",
    "  'User-Agent'\n",
    "]\n",
    "df_selected = df_selected.drop(columns=del_columns, axis=1)\n",
    "display(df_selected.head())\n",
    "display(df_selected.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bd1a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sustituir NaN por cadena vacía\n",
    "df_selected['content_missing'] = df_selected['content'].isna()\n",
    "df_selected['content'] = df['content'].fillna('')\n",
    "display(df_selected.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165b9522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de una columna 'content-lenght' que aplique la función len a la columna content\n",
    "df_selected['content_length'] = df_selected['content'].fillna('').str.len()\n",
    "display(df_selected.head())\n",
    "display(df_selected.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f4700",
   "metadata": {},
   "source": [
    "**Definición de Funciones Útiles para Extraer Características del Access Log**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e21762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_sql_words(url):\n",
    "  \"Cuenta palabras relacionadas con SQL Injection\" \n",
    "  sql_words = [\n",
    "    r'SELECT', \n",
    "    r'FROM', \n",
    "    r'WHERE', \n",
    "    r'DELETE', \n",
    "    r'DROP', \n",
    "    r'CREATE', \n",
    "    r'TABLE', \n",
    "    r'LIKE', \n",
    "    r'UNION', \n",
    "    r'INSERT', \n",
    "    r'UPDATE', \n",
    "    r'ALTER',\n",
    "    r'INTO', \n",
    "    r'VALUES', \n",
    "    r'SET', \n",
    "    r'JOIN', \n",
    "    r'GRANT', \n",
    "    r'REVOKE'\n",
    "  ]\n",
    "  pattern = re.compile('|'.join(sql_words), re.IGNORECASE)\n",
    "  matches = pattern.findall(str(url))\n",
    "  return len(matches)\n",
    "\n",
    "def count_xss_words(url):\n",
    "  \"Cuenta palabras relacionadas con Cross-Site Scripting (XSS)\"\n",
    "  xss_words = [\n",
    "    r'script', \n",
    "    r'alert', \n",
    "    r'javascript', \n",
    "    r'onerror', \n",
    "    r'onload', \n",
    "    r'onunload', \n",
    "    r'prompt', \n",
    "    r'confirm', \n",
    "    r'eval', \n",
    "    r'expression',\n",
    "    r'function\\(', \n",
    "    r'xmlhttprequest', \n",
    "    r'xhr', \n",
    "    r'window\\.', \n",
    "    r'document\\.', \n",
    "    r'iframe', \n",
    "    r'src=', \n",
    "    r'cookie', \n",
    "    r'document\\.cookie',\n",
    "    r'set-cookie', \n",
    "    r'click', \n",
    "    r'mouseover'\n",
    "  ]\n",
    "  pattern = re.compile('|'.join(xss_words), re.IGNORECASE)\n",
    "  matches = pattern.findall(str(url))\n",
    "  return len(matches)\n",
    "\n",
    "def count_command_words(url): \n",
    "  \"Cuenta palabras relacionadas con ejecución de comandos\"\n",
    "  command_words = [\n",
    "    r'cmd', \n",
    "    r'dir', \n",
    "    r'shell', \n",
    "    r'exec', \n",
    "    r'cat', \n",
    "    r'etc', \n",
    "    r'tmp',\n",
    "    r'bin', \n",
    "    r'bash', \n",
    "    r'sh', \n",
    "    r'python', \n",
    "    r'perl', \n",
    "    r'ruby', \n",
    "    r'php',\n",
    "    r'\\.exe', \n",
    "    r'\\.php', \n",
    "    r'\\.js', \n",
    "    r'\\.py', \n",
    "    r'\\.pl', \n",
    "    r'\\.rb',\n",
    "    r'system\\(', \n",
    "    r'popen\\(', \n",
    "    r'proc_open\\(', \n",
    "    r'passthru\\('\n",
    "  ]\n",
    "  pattern = re.compile('|'.join(command_words), re.IGNORECASE)\n",
    "  matches = pattern.findall(str(url))\n",
    "  return len(matches)\n",
    "\n",
    "def count_auth_words(url):\n",
    "  \"Cuenta palabras relacionadas con autentificación\"\n",
    "  auth_words = [\n",
    "    r'admin', \n",
    "    r'administrator', \n",
    "    r'password', \n",
    "    r'login', \n",
    "    r'pwd',\n",
    "    r'credential', \n",
    "    r'user', \n",
    "    r'username', \n",
    "    r'passwd', \n",
    "    r'secret',\n",
    "    r'token', \n",
    "    r'session', \n",
    "    r'auth', \n",
    "    r'authentication', \n",
    "    r'key'\n",
    "  ]\n",
    "  pattern = re.compile('|'.join(auth_words), re.IGNORECASE)\n",
    "  matches = pattern.findall(str(url))\n",
    "  return len(matches)\n",
    "\n",
    "def count_error_words(url):\n",
    "  \"Cuenta palabras relacionadas con errores\"\n",
    "  e_words = [\n",
    "    r'error', \n",
    "    r'errorMsg', \n",
    "    r'errorID', \n",
    "    r'incorrect', \n",
    "    r'fail',\n",
    "    r'failed', \n",
    "    r'failure', \n",
    "    r'exception', \n",
    "    r'stack',\n",
    "    r'trace',\n",
    "    r'debug', \n",
    "    r'warning', \n",
    "    r'fatal', \n",
    "    r'crash',\n",
    "    r'invalid'\n",
    "  ]\n",
    "  pattern = re.compile('|'.join(e_words), re.IGNORECASE)\n",
    "  matches = pattern.findall(str(url))\n",
    "  return len(matches)\n",
    "\n",
    "def count_malware_words(url):\n",
    "  \"Cuenta palabras relacionadas con malware\"\n",
    "  malware_words = [\n",
    "    r'malware', \n",
    "    r'ransomware', \n",
    "    r'phishing', \n",
    "    r'exploit', \n",
    "    r'virus',\n",
    "    r'trojan', \n",
    "    r'backdoor', \n",
    "    r'spyware', \n",
    "    r'rootkit', \n",
    "    r'worm',\n",
    "    r'adware', \n",
    "    r'keylogger', \n",
    "    r'botnet', \n",
    "    r'payload', \n",
    "    r'inject',\n",
    "    r'injected', \n",
    "    r'hacker', \n",
    "    r'attack', \n",
    "    r'exploit', \n",
    "    r'breach'\n",
    "  ]\n",
    "  pattern = re.compile('|'.join(malware_words), re.IGNORECASE)\n",
    "  matches = pattern.findall(str(url))\n",
    "  return len(matches)\n",
    "\n",
    "def count_danger_characters(url):\n",
    "  \"Cuenta caracteres potencialmente peligrosos\"\n",
    "  characters = [\n",
    "    r\"'\", \n",
    "    r\"--\", \n",
    "    r\";\", \n",
    "    r\"\\\\\", \n",
    "    r\"\\\"\", \n",
    "    r\"<\", \n",
    "    r\">\", \n",
    "    r\"(\", \n",
    "    r\")\", \n",
    "    r\"&\", \n",
    "    r\"|\"\n",
    "  ]\n",
    "  count = 0\n",
    "  url_str = str(url)\n",
    "  for c in characters:\n",
    "    count += url_str.count(c)\n",
    "  return count\n",
    "\n",
    "def count_obfuscation_code_words(url):\n",
    "  \"Cuenta técnicas de ofuscación de código\"\n",
    "  obfuscation_words = [\n",
    "    r'encode', \n",
    "    r'decode', \n",
    "    r'base64', \n",
    "    r'hex', \n",
    "    r'urlencode',\n",
    "    r'urldecode', \n",
    "    r'escape', \n",
    "    r'unescape', \n",
    "    r'obfuscate',\n",
    "    r'xor', \n",
    "    r'rot13', \n",
    "    r'chr\\(',\n",
    "    r'char\\(', \n",
    "    r'fromCharCode',\n",
    "    r'eval\\('\n",
    "  ]\n",
    "  pattern = re.compile('|'.join(obfuscation_words), re.IGNORECASE)\n",
    "  matches = pattern.findall(str(url))\n",
    "  return len(matches)\n",
    "\n",
    "def count_dir_words(url):\n",
    "  \"Cuenta referencias a directorios sensibles\"\n",
    "  dir_words = [\n",
    "    r'\\.\\./', \n",
    "    r'\\.\\.\\\\', \n",
    "    r'/etc/', \n",
    "    r'/bin/', \n",
    "    r'/tmp/', \n",
    "    r'/var/',\n",
    "    r'/home/', \n",
    "    r'/root/', \n",
    "    r'proc/', \n",
    "    r'dev/', \n",
    "    r'boot/', \n",
    "    r'usr/', \n",
    "    r'lib/', \n",
    "    r'sbin/'\n",
    "  ]\n",
    "  pattern = re.compile('|'.join(dir_words), re.IGNORECASE)\n",
    "  matches = pattern.findall(str(url))\n",
    "  return len(matches)\n",
    "\n",
    "def count_dot(url):\n",
    "  \"Cuenta la cantidad de puntos en la URL\"\n",
    "  count_dot = url.count('.')\n",
    "  return count_dot\n",
    "\n",
    "def count_http(url): \n",
    "  \"Cuenta las ocurrencias de http en la URL\"\n",
    "  return url.count('http')\n",
    "\n",
    "def count_percentage_symbol(url):\n",
    "  \"Cuenta los signos de porcentaje\"\n",
    "  return url.count('%')\n",
    "\n",
    "def count_question_symbol(url):\n",
    "  \"Cuenta los signos de interrogación\"\n",
    "  return url.count('?')\n",
    "\n",
    "def count_hyphen(url):\n",
    "  \"Cuenta guiones (-) en la URL\"\n",
    "  return url.count('-')\n",
    "\n",
    "def count_equal(url):\n",
    "  \"Cuenta signos igual (=)\"\n",
    "  return url.count('=')\n",
    "\n",
    "def url_length(url):\n",
    "  \"Retorna la longitud total de la URL\"\n",
    "  return len(str(url))\n",
    "\n",
    "def digit_count(url):\n",
    "  \"Cuenta la cantidad de dígitos numéricos en la URL\"\n",
    "  digits = 0\n",
    "  for i in url:\n",
    "    if i.isnumeric():\n",
    "      digits = digits + 1\n",
    "  return digits\n",
    "\n",
    "def letter_count(url):\n",
    "  \"Cuenta la cantidad de letras en la URL\"\n",
    "  letters = 0\n",
    "  for i in url:\n",
    "    if i.isalpha():\n",
    "      letters += 1\n",
    "  return letters\n",
    "\n",
    "def count_special_characters(url):\n",
    "  \"Cuenta caracteres especiales (no alfanuméricos) usando regex\"\n",
    "  special_characters = re.sub(r'[a-zA-Z0-9\\s]', '', url)\n",
    "  count = len(special_characters)\n",
    "  return count\n",
    "\n",
    "def is_encoded(url):\n",
    "  \"\"\"Detecta si la URL está codificada (presencia de %)\n",
    "\n",
    "  Returns:\n",
    "    int: Retorna 1 si es verdadero (URL está codificada) y 0 si no\n",
    "  \"\"\"\n",
    "  return int('%' in url.lower())\n",
    "\n",
    "def unusual_character_ratio(url):\n",
    "  \"Calcula la proporción de caracteres inusuales (no alfanuméricos, guiones, puntos o guiones bajos) respecto a la longitud total\"\n",
    "  total_characters = len(url)\n",
    "  unusual_characters = re.sub(r'[a-zA-Z0-9\\s\\-._]', '', url)\n",
    "  unusual_count = len(unusual_characters)\n",
    "  ratio = unusual_count / total_characters if total_characters > 0 else 0\n",
    "  return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e4d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features_functions: List[Callable] = [\n",
    "  count_sql_words,\n",
    "  count_xss_words, \n",
    "  count_command_words, \n",
    "  count_auth_words, \n",
    "  count_error_words,\n",
    "  count_malware_words,\n",
    "  count_danger_characters,\n",
    "  count_obfuscation_code_words,\n",
    "  count_dir_words,\n",
    "  count_dot,\n",
    "  count_http,\n",
    "  count_percentage_symbol,\n",
    "  count_question_symbol,\n",
    "  count_hyphen,\n",
    "  count_equal,\n",
    "  url_length,\n",
    "  digit_count,\n",
    "  letter_count,\n",
    "  count_special_characters,\n",
    "  is_encoded,\n",
    "  unusual_character_ratio\n",
    "]\n",
    "\n",
    "extract_request_features = True \n",
    "extract_content_features = False \n",
    "request_columns_name = []\n",
    "content_columns_name = []\n",
    "for func in extract_features_functions:\n",
    "  if extract_request_features:\n",
    "    feat_name = f\"request_{func.__name__}\"\n",
    "    df_selected[feat_name] = df_selected['content'].apply(func)\n",
    "    request_columns_name.append(feat_name)\n",
    "  if extract_content_features:\n",
    "    feat_name = f\"content_{func.__name__}\"\n",
    "    df_selected[feat_name] = df_selected['request_url'].apply(func)\n",
    "    content_columns_name.append(feat_name)\n",
    "\n",
    "display(df_selected.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f8025b",
   "metadata": {},
   "source": [
    "**Codificación de Variable Categóricas**: `Class` y `Method`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f77ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "df_selected['Class_encoded']  = encoder.fit_transform(df_selected['Class'] )\n",
    "df_selected['Method_encoded'] = encoder.fit_transform(df_selected['Method'])\n",
    "print(f\"Number of unique values for 'Class_encoded':  {df_selected['Class_encoded'].nunique() }\")\n",
    "print(f\"Number of unique values for 'Method_encoded': {df_selected['Method_encoded'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d783c009",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d9567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all(df_selected['content_length'] == df_selected['content_url_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d0ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_labels = ['Method_encoded', 'content_length'] + request_columns_name + content_columns_name\n",
    "y_label = 'Class_encoded'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3abfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train,y_test = train_test_split(\n",
    "  df_selected[X_labels], \n",
    "  df_selected[y_label], \n",
    "  test_size=0.3, \n",
    "  random_state=43, \n",
    "  stratify=df_selected[y_label]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d08c94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model = RandomForestClassifier(random_state=1000)\n",
    "RF_model.fit(X_train,y_train)\n",
    "\n",
    "selector = SelectFromModel(RF_model, threshold=\"mean\")\n",
    "selector.fit(X_train, y_train)\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected  = selector.transform(X_test )\n",
    "\n",
    "SVM_model = SVC(kernel='rbf', C=2, gamma='scale')\n",
    "SVM_model.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb32aa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = SVM_model.predict(X_test_selected)\n",
    "accuracy = accuracy_score(y_test, y_pred) \n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e90ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = RF_model.predict(X_test)\n",
    "print(f\"\"\"Resultados de Random Forest \n",
    "MAE:          {mean_absolute_error(y_test, y_pred)}\n",
    "Accuracy:     {accuracy_score(y_test, y_pred)} \n",
    "Precision:    {precision_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))}\n",
    "Recall:       {recall_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))}\n",
    "F1-Score:     {f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))}\n",
    "ROC AUC:      {roc_auc_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))}\n",
    "\"\"\")\n",
    "\n",
    "error_rate = (y_pred != y_test).mean()\n",
    "print(\"Test error: {:.1%}\".format(error_rate))\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names= ['Normal', 'Anomalous']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8266e858",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['Normal', 'Anomalous']\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = pd.DataFrame(cm, index=['0', '1'], columns=['0', '1'])\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cm, cmap=\"Blues\", linecolor='black', linewidth=1, annot=True, fmt='', xticklabels=label, yticklabels=label)\n",
    "plt.title(\"Random Forest\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64b9629",
   "metadata": {},
   "source": [
    "**Observaciones**: \n",
    "- Aplicar las funciones de extracción de características al content y tomarlas como características mejora mucho el modelo \n",
    "- *Problema*: en access logs como se puede extraer el content?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
