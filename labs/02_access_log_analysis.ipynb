{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96fade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "# Ejecutar antes las celdas de `01_access_log_parsing` o elige una ubicación donde exista un archivo de access logs (Apache Combined Log Format) \n",
    "log_file_path = '../data/target/access_log_master.log'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992b9147",
   "metadata": {},
   "source": [
    "## Load Access Log File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58f04c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambia a None para cargar todos los datos, o a un número para establecer un límite\n",
    "n_samples = None \n",
    "\n",
    "with open(log_file_path, 'r') as f:\n",
    "  if n_samples is not None: \n",
    "    sample_lines = []\n",
    "    for _ in range(n_samples):\n",
    "      line = f.readline()\n",
    "      \n",
    "      # si se acaba el archivo antes de alcanzar el número de muestras definidas\n",
    "      if not line:    \n",
    "        break \n",
    "      sample_lines.append(line.strip())\n",
    "  else: \n",
    "    # Cargar todas las líneas\n",
    "    sample_lines = [line.strip() for line in f]\n",
    "\n",
    "print(f\"Sample log lines (Total: {len(sample_lines)}):\")\n",
    "for i,line in enumerate(sample_lines[:10], 1):\n",
    "  print(f\"{i:>{len(str(n_samples))}}) {line}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900bfca2",
   "metadata": {},
   "source": [
    "## Load and Parsing a Access Log File using `lars`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a3daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import warnings\n",
    "from lars.apache import ApacheSource, COMBINED, ApacheWarning\n",
    "\n",
    "parsed_logs = []\n",
    "conflicting_logs = {}\n",
    "problematic_logs = {}\n",
    "\n",
    "# Leer todas las lineas primero\n",
    "with open(log_file_path, 'r') as f:\n",
    "  all_lines = f.readlines()\n",
    "\n",
    "# usar catch-warning para capturar advertencias\n",
    "with warnings.catch_warnings(record=True) as w:\n",
    "  # convertir todas las advertencias en excepciones o capturarlas\n",
    "  warnings.simplefilter(\"always\", ApacheWarning)\n",
    "\n",
    "  with open(log_file_path) as f:\n",
    "    with ApacheSource(f, log_format=COMBINED) as source:\n",
    "      for i,row in enumerate(source, 1):\n",
    "        try:\n",
    "          record = {\n",
    "            \"remote_host\" : row.remote_host,\n",
    "            \"ident\" : row.ident,\n",
    "            \"remote_user\" : row.remote_user, \n",
    "            \"time\" : row.time,\n",
    "            \"request_method\" : row.request.method,\n",
    "            \"request_url_scheme\" : row.request.url.scheme, \n",
    "            \"request_url_netloc\" : row.request.url.netloc,\n",
    "            \"request_url_path_str\" : row.request.url.path_str,\n",
    "            \"request_url_params\" : row.request.url.params, \n",
    "            \"request_url_query_str\" : row.request.url.query_str,\n",
    "            \"request_url_fragment\" : row.request.url.fragment,\n",
    "            \"request_protocol\": row.request.protocol,\n",
    "            \"status\" : row.status,\n",
    "            \"size\" : row.size,\n",
    "            \"req_Referer\" : row.req_Referer,\n",
    "            \"req_User_agent\" : row.req_User_agent\n",
    "          }\n",
    "          parsed_logs.append(record)\n",
    "        except Exception as e:\n",
    "          #print(f\"Error en fila {i}: {e}\")\n",
    "          conflicting_logs[i] = {\n",
    "            'error': str(e), \n",
    "            'line_content': all_lines[i-1].strip() if i <= len(all_lines) else \"no disponible\"\n",
    "          }\n",
    "  \n",
    "  # procesar las advertencias capturadas\n",
    "  for warning in w:\n",
    "    if issubclass(warning.category, ApacheWarning):\n",
    "      msg = str(warning.message)\n",
    "      match = re.search(r'Line (\\d+):', msg)\n",
    "      if match:\n",
    "        line_num = int(match.group(1))\n",
    "        if line_num <= len(all_lines):\n",
    "            problematic_logs[line_num] = {\n",
    "              'line_content': all_lines[line_num - 1].strip(),\n",
    "              'warning_message': msg, \n",
    "              'category': warning.category.__name__,\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c166cbb",
   "metadata": {},
   "source": [
    "Mientras que `conflicting_logs` captura logs con errores menores que impiden procesar completamente una línea. Estos fallos en la extracción se debe a errores en la consulta (`request.url`) que puede deberse a logs malignos. En cambio, `problematic_logs` captura logs con problemas mayores, lo cual es motivo para que no se parseen los logs (no se encuentran en `parsed_logs`). Los logs se pueden considerar en una primera instancia como anomalías debido a que no siguen la estructura común de los Apache access logs de formato combinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094f2d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for warning in list(problematic_logs.items())[:10]:\n",
    "  idx = warning[0]\n",
    "  line_content = warning[1]['line_content']\n",
    "  print(f\"{idx}) {line_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50332861",
   "metadata": {},
   "source": [
    "Dentro de los logs problemáticos se notan se forma rápida:\n",
    "- No presentan un método HTTP válido (como GET, POST, etc) o simplemente NO presentan uno\n",
    "- Presentan un comportamiento sospechoso como: No hay presencia de Referer ni User-Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c9b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse import parse \n",
    "\n",
    "pattern = '{ip_client} {ident} {auth_user} [{timestamp}] \"{method} {request} {protocol}\" {status:d} {size:d} \"{referrer}\" \"{agent}\"'\n",
    "\n",
    "parsed_logs = []\n",
    "for conflict in list(conflicting_logs.items()):\n",
    "  idx = conflict[0]\n",
    "  line_content = conflict[1]['line_content']\n",
    "  try: \n",
    "    parsed = parse(pattern, line_content.strip())\n",
    "    parsed_logs.append(parsed.named)\n",
    "  except Exception as e:\n",
    "    print(f\"Line {idx}: {line_content}\")\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1947a11e",
   "metadata": {},
   "source": [
    "A pesar de que con `lars` los logs pertenecientes a `conflicting logs` no se logran parsear correctamente, se pudo hacer ese proceso con `parse`. La diferencia principal entre ambas es en la forma de extraer las características de la petición (`request` en el patrón diseñado para `parse` y `request.url` para `lars`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756f96af",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_problematic_logs =  len(problematic_logs.keys())\n",
    "total_conflicting_logs =  len(conflicting_logs.keys())\n",
    "total_logs = len(parsed_logs) + total_problematic_logs + total_conflicting_logs \n",
    "\n",
    "print(f\"Total: {total_logs}\")\n",
    "print(f\"Cantidad de Problematic Logs: {total_problematic_logs} ({(total_problematic_logs / total)*100 if total != 0 else 0}%)\")\n",
    "print(f\"Cantidad de Conflicting Logs: {total_conflicting_logs} ({(total_conflicting_logs / total)*100 if total != 0 else 0}%)\")\n",
    "print(f\"Cantidad de Parsed Logs: {len(parsed_logs)} ({(len(parsed_logs) / total)*100 if total != 0 else 0}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3335ff",
   "metadata": {},
   "source": [
    "### Análisis de Logs Problemáticos\n",
    "\n",
    "Estos logs deben ser analizados porque están fuera de lo común y necesitan otra forma de parsear estos y del resultado del parseo entonces analizar características como `status`, `ip-client` y `user-agent` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abbaea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = max(problematic_logs.keys())\n",
    "\n",
    "logs = list(problematic_logs.items()) \n",
    "\n",
    "for log in logs:\n",
    "  idx = log[0]\n",
    "  line_content = log[1]['line_content']\n",
    "  print(f\"{idx:>{len(str(max_idx))}}) {line_content}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85db9fff",
   "metadata": {},
   "source": [
    "Presentan:\n",
    "- Cadenas bytes en formato hexademical en las solicitudes HTTP (tanto en método, protocolo y url)\n",
    "- No existe Referer, ni User-Agent\n",
    "- Las solicitudes HTTP solo poseen solo método (precisamente GET) \n",
    "- Las pocas solicitudes HTTP (las que no están formadas por bytes en formato hexademical) no presentan método y tienen cadenas muy extrañas, tienen direcciones IP o tienen mensajes JSON-RPC (protocolos de minería de criptomonedas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01012d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse import parse \n",
    "\n",
    "pattern = '{ip_client} {ident} {auth_user} [{timestamp}] {request_http} {status:d} {size:d} \"{referrer}\" \"{agent}\"'\n",
    "\n",
    "parsed_logs = []\n",
    "for problematic in list(problematic_logs.items()):\n",
    "  idx = problematic[0]\n",
    "  line_content = problematic[1]['line_content']\n",
    "  try: \n",
    "    parsed = parse(pattern, line_content.strip())\n",
    "    parsed_logs.append(parsed.named)\n",
    "  except Exception as e:\n",
    "    print(f\"Line {idx}: {line_content}\")\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "df = pd.DataFrame(parsed_logs)\n",
    "status_distribution = df['status'].value_counts().sort_index()\n",
    "display(status_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdea3d2b",
   "metadata": {},
   "source": [
    "**Análisis de Distribución de Código de Estado HTTP**:\n",
    "- `301`: El recurso solicitado tiene una nueva URL permanente \n",
    "- `400`: El servidor no puede entender la solicitud debido a una sintaxis inválida \n",
    "- `408`: El servidor esperó demasiado tiempo a que el cliente enviara la solicitud completa y cerró la conexión inactiva\n",
    "- `499`: El cliente cerro la solicitud antes de que el servidor pudiera responder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1fbf2f",
   "metadata": {},
   "source": [
    "Para códigos 400, se va revisar la dirección IP de origen y el agente de usuario $\\to$ Un alto volumen de errores 400 provenientes de unas pocas IPs o de agentes de usuario inusuales (como herramientas de escaneo) puede indicar actividad maliciosa automatizada. \n",
    "\n",
    "Para códigos 408 y 499: Estos códigos suelen ser síntomas de que algo en el servidor no funciona de manera óptima $\\to$ Un aumento repentino suele estar relacionado con una alta carga en el servidor, tiempos de respuesta lentos en la aplicación o problemas de red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e079f254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar logs con los códigos de estado de interés\n",
    "status_codes_to_check = [400, 408, 499]\n",
    "filtered_logs = df[df['status'].isin(status_codes_to_check)]\n",
    "\n",
    "# Agrupar por IP para identificar posibles orígenes problemáticos\n",
    "ip_analysis = filtered_logs.groupby(['status', 'ip_client']).size().reset_index(name='count')\n",
    "print(ip_analysis.sort_values(by='count', ascending=False).head(20))  # Ver las 20 IPs más activas\n",
    "\n",
    "# Agrupar por agente de usuario\n",
    "agent_analysis = filtered_logs.groupby(['status', 'agent']).size().reset_index(name='count')\n",
    "print(agent_analysis.sort_values(by='count', ascending=False).head(10))  # Ver los 10 agentes más comunes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a027d5a",
   "metadata": {},
   "source": [
    "Estos resultados muestran una **actividad maliciosa**: patrón de cientos de errores 400, concentrados en pocas IPs, cada una con rangos muy diferentes, y con agente vacío, no es un comportamiento normal de un usuario o buscador. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40e0a8c",
   "metadata": {},
   "source": [
    "## Análisis Exploratorio de Datos sobre Access Log Master File\n",
    "\n",
    "Debido a que los logs conflictivos se pudieron parsear correctamente con el siguiente patrón y `parse`.  \n",
    "\n",
    "`'{ip_client} {ident} {auth_user} [{timestamp}] \"{method} {request} {protocol}\" {status:d} {size:d} \"{referrer}\" \"{agent}\"'`\n",
    "\n",
    "Entonces se va a parsear todos los access log con este patrón desde el archivo inicial y se va a guardar los resultados en un dataframe y guardar este en un archivo CSV. Luego se va a preprocesar la información que proporciona este archivo de logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff66276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar los logs que se conocen que son maliciosos \n",
    "# Parsear primero todos los access log (ya están cargados en una de las primeras celdas), se tiene que solamente introducir el patrón y parsear todos los logs\n",
    "# Agregar una característica adicional (method+request+protocol) porque con esta característica se puede guardar la petición HTTP de las solicitudes maliciosas\n",
    "# Finalmente se parsean los logs maliciosos y se agregan al dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb8f0d6",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "- Análisis Exploratorio de Datos sobre los DataFrames\n",
    "  - Distribución de Tiempo y Consulta (saber la densidad de consulta por día)\n",
    "  - Distribución de `method`, `protocol`, `status`, `size`, `referer`, `user_agent`\n",
    "  - "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
