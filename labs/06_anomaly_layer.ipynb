{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad0e7163",
   "metadata": {},
   "source": [
    "### Capa 2: Sistema de Detección de Anomalías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be392da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "# Para evitar warnings de convergencia\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Agregamos importaciones para validación cruzada y fine-tuning\n",
    "from sklearn.model_selection import (\n",
    "  train_test_split,\n",
    "  StratifiedKFold,          # Validación cruzada estratificada\n",
    "  GridSearchCV,\n",
    "  RandomizedSearchCV,       # Para optimización de hiperparámetros\n",
    "  cross_val_score,\n",
    "  cross_val_predict\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "  StandardScaler,\n",
    "  RobustScaler,\n",
    "  LabelEncoder\n",
    ")\n",
    "from sklearn.ensemble import (\n",
    "  RandomForestClassifier, \n",
    "  IsolationForest\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import (\n",
    "  SVC\n",
    ")\n",
    "from sklearn.neural_network import (\n",
    "  MLPClassifier\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "  classification_report, \n",
    "  confusion_matrix,\n",
    "  roc_auc_score,\n",
    "  roc_curve,\n",
    "  precision_recall_curve,\n",
    "  f1_score,\n",
    "  recall_score, \n",
    "  precision_score,\n",
    "  accuracy_score,\n",
    "  precision_recall_fscore_support   # Métricas adicionales\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Para optimización de hiperparámetros\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "\n",
    "# Configuración de estilo para las gráficas\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e0aa47",
   "metadata": {},
   "source": [
    "### Cargar Datos, Preparación de Datos y Codificación de Variable `method`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dedaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_mlab_path = '../data/target/access_log_master_manual_labeling.csv'\n",
    "df = pd.read_csv(log_mlab_path)\n",
    "\n",
    "print(\"Distribución de clases original:\")\n",
    "display(df['anomaly'].value_counts())\n",
    "\n",
    "df_labeled = df[df['anomaly'] != -1].copy()\n",
    "print(\"Datos etiquetados para entrenamiento:\")\n",
    "display(df_labeled['anomaly'].value_counts())\n",
    "display(df_labeled.shape)\n",
    "\n",
    "# Codificar variable 'method'\n",
    "method_series = df_labeled['method']\n",
    "method_series = method_series.fillna('UNKNOWN')\n",
    "method_encoder = LabelEncoder()\n",
    "df_labeled['method_encoded'] = method_encoder.fit_transform(method_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf9c187",
   "metadata": {},
   "source": [
    "### Definición de Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eac6eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feat = [\n",
    "  'size', \n",
    "  'url__count_sql_words',\n",
    "  'url__count_xss_words', \n",
    "  'url__count_command_words',\n",
    "  'url__count_auth_words', \n",
    "  'url__count_error_words',\n",
    "  'url__count_malware_words', \n",
    "  'url__count_danger_characters',\n",
    "  'url__count_obfuscation_code_words',\n",
    "  'url__count_dir_words',\n",
    "  'url__count_dot',\n",
    "  'url__count_http',\n",
    "  'url__count_percentage_symbol',\n",
    "  'url__count_question_symbol', \n",
    "  'url__count_hyphen', \n",
    "  'url__count_equal',\n",
    "  'url__url_length', \n",
    "  'url__digit_count', \n",
    "  'url__letter_count',\n",
    "  'url__count_special_characters', \n",
    "  'url__is_encoded',\n",
    "  'url__unusual_character_ratio'\n",
    "]\n",
    "cat_feat = [ 'method_encoded' ]\n",
    "\n",
    "X = df_labeled[num_feat + cat_feat]\n",
    "X_cat = df_labeled[cat_feat]\n",
    "y = df_labeled['anomaly']\n",
    "\n",
    "print(f\"Características seleccionadas: {len(num_feat + cat_feat)}\")\n",
    "print(f\"Dimensión de X: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c985d",
   "metadata": {},
   "source": [
    "### Escalado de Datos\n",
    "\n",
    "Como se quiere crear un sistema de detección de anomalías y los logs que presentan anomalías pueden contener características inusuales (valores extremos como alto valor en la variable de `badword_ratio`), `RobustScaler` es una buena opción porque las anomalías pueden aparecer como outliers en los datos y no se quiere que esas anomalías distorsionen el escalado de todas las muestras normales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8279636",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X[num_feat])\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=num_feat, index=X.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c909ced9",
   "metadata": {},
   "source": [
    "Usar datos escalados para los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8385aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_scaled_df\n",
    "X[cat_feat] = X_cat[cat_feat]\n",
    "display(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b248d9b",
   "metadata": {},
   "source": [
    "### Funciones de Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa4a0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_scaling(model, X, y, cv=5, random_state=42):\n",
    "  \"\"\"Evalúa un modelo de aprendizaje supervisado con escalado, SMOTE y validación cruzada estratificada.\n",
    "\n",
    "  Args:\n",
    "    model: Modelo de sklearn\n",
    "    X: Características escaladas\n",
    "    y: Etiquetas\n",
    "    cv: Número de folds\n",
    "    random_state: Parámetro de Aleatoriedad\n",
    "\n",
    "  Returns:\n",
    "    Diccionario con métricas promedio y globales\n",
    "  \"\"\"\n",
    "  skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=random_state)\n",
    "\n",
    "  # Crear pipeline (SMOTE se aplica solo durante entrenamiento)\n",
    "  pipeline = ImbPipeline([\n",
    "    ('smote', SMOTE(random_state=random_state)),\n",
    "    ('classifier', model)\n",
    "  ])\n",
    "\n",
    "  accuracies, aucs, precisions, recalls, f1_scores = [], [], [], [], []\n",
    "  y_true_all, y_pred_all, y_pred_proba_all = [], [], []\n",
    "\n",
    "  for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # Entrenar pipeline\n",
    "    with warnings.catch_warnings():\n",
    "      warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "      pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Predecir\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "    y_pred_proba = pipeline.predict_proba(X_val)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    # Métricas del fold\n",
    "    accuracies.append(accuracy_score(y_val, y_pred))\n",
    "    if y_pred_proba is not None:\n",
    "      aucs.append(roc_auc_score(y_val, y_pred_proba))\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_val, y_pred, average='binary', pos_label=1, zero_division=0)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    # Acumular para métricas globales\n",
    "    y_true_all.extend(y_val)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    if y_pred_proba is not None:\n",
    "      y_pred_proba_all.extend(y_pred_proba)\n",
    "\n",
    "  # Métricas promedio de CV\n",
    "  cv_metrics = {\n",
    "    'accuracy': f\"{np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\",\n",
    "    'auc': f\"{np.mean(aucs):.4f} ± {np.std(aucs):.4f}\" if aucs else \"N/A\",\n",
    "    'precision': f\"{np.mean(precisions):.4f} ± {np.std(precisions):.4f}\",\n",
    "    'recall': f\"{np.mean(recalls):.4f} ± {np.std(recalls):.4f}\",\n",
    "    'f1': f\"{np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\"\n",
    "  }\n",
    "\n",
    "  # Métricas globales\n",
    "  global_metrics = {\n",
    "    'accuracy': accuracy_score(y_true_all, y_pred_all),\n",
    "    'auc': roc_auc_score(y_true_all, y_pred_proba_all) if y_pred_proba_all else None,\n",
    "    'precision': precision_recall_fscore_support(y_true_all, y_pred_all, average='binary', pos_label=1, zero_division=0)[0],\n",
    "    'recall': precision_recall_fscore_support(y_true_all, y_pred_all, average='binary', pos_label=1, zero_division=0)[1],\n",
    "    'f1': precision_recall_fscore_support(y_true_all, y_pred_all, average='binary', pos_label=1, zero_division=0)[2],\n",
    "    'confusion_matrix': confusion_matrix(y_true_all, y_pred_all)\n",
    "  }\n",
    "\n",
    "  return cv_metrics, global_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeb067f",
   "metadata": {},
   "source": [
    "### Definición de Modelos para Entrenamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dd47f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bed26cb",
   "metadata": {},
   "source": [
    "#### Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07177ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['LogisticRegression'] = LogisticRegression(\n",
    "  random_state=42,\n",
    "  max_iter=1000,  \n",
    "  solver='lbfgs', \n",
    "  C=0.1,  \n",
    "  class_weight='balanced', \n",
    "  verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5578a24",
   "metadata": {},
   "source": [
    "#### Clasificador Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0911ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['RandomForestClassifier'] = RandomForestClassifier(\n",
    "  random_state=42,\n",
    "  n_estimators=100,  \n",
    "  class_weight='balanced_subsample',  # Mejor manejo de clases\n",
    "  max_depth=None,\n",
    "  min_samples_split=5,\n",
    "  min_samples_leaf=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcad5eb",
   "metadata": {},
   "source": [
    "#### Clasificador XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd57c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['XGBClassifier'] = XGBClassifier(\n",
    "  random_state=42,\n",
    "  eval_metric='logloss',\n",
    "  scale_pos_weight=len(y[y==0]) / len(y[y==1]), # Balancear clases\n",
    "  n_estimators=200,\n",
    "  max_depth=6,\n",
    "  learning_rate=0.1,\n",
    "  subsample=0.8,\n",
    "  colsample_bytree=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac310d8b",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ca0ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['SVM'] = SVC(\n",
    "  random_state=42,\n",
    "  kernel='linear',\n",
    "  C=1.0,\n",
    "  class_weight='balanced',\n",
    "  probability=True,  # Necesario para AUC\n",
    "  max_iter=300,\n",
    "  verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758e3ae2",
   "metadata": {},
   "source": [
    "### Evaluación de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2472cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for name,model in models.items():\n",
    "  print(f\"Entrenamiento del Modelo: {name}\")\n",
    "  cv_metrics, global_metrics = evaluate_model_with_scaling(model, X, y, cv=5)\n",
    "  results[name] = {\n",
    "    'cv': cv_metrics, \n",
    "    'global': global_metrics\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d7eb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,result in results.items():\n",
    "  print(f\"Model: {name}\")\n",
    "  for metric, value in result['global'].items():\n",
    "    print(f\" {metric}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b877bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Métricas CV (promedio ± std)\")\n",
    "for metric, value in cv_metrics.items():\n",
    "  print(f\" {metric.capitalize()}: {value}\")\n",
    "\n",
    "print(f\"\"\"Métricas totales (concatenado de todos los folds):\n",
    "  Accuracy:  {global_metrics['accuracy']:.4f}\n",
    "  Precision: {global_metrics['precision']:.4f}\n",
    "  Recall:    {global_metrics['recall']:.4f}\n",
    "  F1:        {global_metrics['f1']:.4f}\n",
    "\"\"\")\n",
    "# NO Metrica AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaeb1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(\n",
    "  random_state=42,\n",
    "  n_estimators=100,  \n",
    "  class_weight='balanced_subsample',  # Mejor manejo de clases\n",
    "  max_depth=None,\n",
    "  min_samples_split=5,\n",
    "  min_samples_leaf=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51bd1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_metrics, global_metrics = evaluate_model_with_scaling(model, X, y, cv=5)\n",
    "results['RandomForestClassifier'] = {\n",
    "  'cv': cv_metrics, \n",
    "  'global': global_metrics\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f77c779",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Métricas CV (promedio ± std)\")\n",
    "for metric, value in cv_metrics.items():\n",
    "  print(f\" {metric.capitalize()}: {value}\")\n",
    "\n",
    "print(f\"\"\"Métricas totales (concatenado de todos los folds):\n",
    "  Accuracy:  {global_metrics['accuracy']:.4f}\n",
    "  Precision: {global_metrics['precision']:.4f}\n",
    "  Recall:    {global_metrics['recall']:.4f}\n",
    "  F1:        {global_metrics['f1']:.4f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bf7516",
   "metadata": {},
   "source": [
    "### Fine-Tuning con RandomizedSearchCV "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93efa170",
   "metadata": {},
   "source": [
    "#### Optimización de Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8458d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_param_dist = [\n",
    "  {  # Para penalty='l2'\n",
    "    'classifier__C': loguniform(1e-3, 1e2),\n",
    "    'classifier__solver': ['lbfgs', 'newton-cg', 'sag', 'saga'],\n",
    "    'classifier__max_iter': [2000, 3000, 5000],\n",
    "    'classifier__class_weight': [None, 'balanced'],\n",
    "    'classifier__penalty': ['l2']\n",
    "  },\n",
    "  {  # Para penalty=None (sin regularización)\n",
    "    'classifier__solver': ['lbfgs', 'newton-cg', 'sag', 'saga'],\n",
    "    'classifier__max_iter': [2000, 3000, 5000],\n",
    "    'classifier__class_weight': [None, 'balanced'],\n",
    "    'classifier__penalty': [None]\n",
    "  }\n",
    "]\n",
    "\n",
    "lr_pipeline = ImbPipeline([\n",
    "  ('smote', SMOTE(random_state=42)),\n",
    "  ('classifier', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "lr_random = RandomizedSearchCV(\n",
    "  lr_pipeline,\n",
    "  param_distributions=lr_param_dist,\n",
    "  n_iter=20,\n",
    "  cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),  # 3 folds para velocidad\n",
    "  scoring='f1',\n",
    "  refit=True,\n",
    "  n_jobs=-1,\n",
    "  verbose=0,\n",
    "  random_state=42\n",
    ")\n",
    "\n",
    "# Entrenar con warnings suprimidos\n",
    "with warnings.catch_warnings():\n",
    "  warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "  warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "  lr_random.fit(X, y)\n",
    "\n",
    "print(f\"\"\"Resultados del Fine-Tuning de Hiperparámetros de Regresión Logística (Optimización de Regresión Logística)\n",
    "Mejores Parámetros LR:  {lr_random.best_params_}\n",
    "Mejor F1-Score:         {lr_random.best_score_:.4f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a0beac",
   "metadata": {},
   "source": [
    "#### Optimización de Clasificador Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b445ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_dist = {\n",
    "  'classifier__n_estimators': randint(100, 500),\n",
    "  'classifier__max_depth': [10, 20, 30, None],\n",
    "  'classifier__min_samples_split': randint(2, 20),\n",
    "  'classifier__min_samples_leaf': randint(1, 10),\n",
    "  'classifier__max_features': ['sqrt', 'log2', None],\n",
    "  'classifier__class_weight': [None, 'balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "rf_pipeline = ImbPipeline([\n",
    "  ('smote', SMOTE(random_state=42)),\n",
    "  ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "rf_random = RandomizedSearchCV(\n",
    "  rf_pipeline,\n",
    "  param_distributions=rf_param_dist,\n",
    "  n_iter=15,\n",
    "  cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "  scoring='f1',\n",
    "  refit=True,\n",
    "  n_jobs=-1,\n",
    "  verbose=0,\n",
    "  random_state=42\n",
    ")\n",
    "\n",
    "# Proceso de Entrenamiento\n",
    "rf_random.fit(X, y)\n",
    "\n",
    "print(f\"\"\"Resultados del Fine-Tuning de Hiperparámetros del Clasificador Random Forest (Optimización del RF Classifier)\n",
    "Mejores Parámetros LR:  {rf_random.best_params_}\n",
    "Mejor F1-Score:         {rf_random.best_score_:.4f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aeb01f",
   "metadata": {},
   "source": [
    "### Comparación y Visualización de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a218384",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "# Modelos optimizados\n",
    "optimized_models = {\n",
    "    'LogisticRegression_Optimized': lr_random.best_estimator_,\n",
    "    'RandomForest_Optimized': rf_random.best_estimator_,\n",
    "    'XGBoost_Default': models['XGBoost']  # Ya estaba bastante configurado\n",
    "}\n",
    "\"\"\"\n",
    "final_results = results\n",
    "for name, model in optimized_models.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    cv_metrics, global_metrics = evaluate_model_with_scaling(\n",
    "        model.named_steps['classifier'] if hasattr(model, 'named_steps') else model,\n",
    "        X, y, cv=5\n",
    "    )\n",
    "    final_results[name] = {'cv': cv_metrics, 'global': global_metrics}\n",
    "    \n",
    "    print(f\"  F1-score (CV): {cv_metrics['f1']}\")\n",
    "    print(f\"  F1-score (Global): {global_metrics['f1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de37c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para gráfico\n",
    "final_results = results\n",
    "model_names = list(final_results.keys())\n",
    "f1_scores = [final_results[name]['global']['f1'] for name in model_names]\n",
    "auc_scores = [final_results[name]['global']['auc'] for name in model_names if final_results[name]['global']['auc']]\n",
    "\n",
    "# Gráfico de comparación\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Gráfico 1: F1 Scores\n",
    "axes[0].bar(model_names, f1_scores, color=['#FF6B6B', '#4ECDC4', '#45B7D1'], alpha=0.8)\n",
    "axes[0].set_title('Comparación de F1-Score (Global)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('F1-Score', fontsize=12)\n",
    "axes[0].set_ylim(0, 1)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Agregar valores encima de las barras\n",
    "for i, v in enumerate(f1_scores):\n",
    "    axes[0].text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Gráfico 2: AUC Scores\n",
    "axes[1].bar(model_names[:len(auc_scores)], auc_scores, color=['#FF6B6B', '#4ECDC4', '#45B7D1'], alpha=0.8)\n",
    "axes[1].set_title('Comparación de AUC (Global)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('AUC', fontsize=12)\n",
    "axes[1].set_ylim(0, 1)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Agregar valores encima de las barras\n",
    "for i, v in enumerate(auc_scores):\n",
    "    axes[1].text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d16bc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===============================\n",
    "# 12. DIAGNÓSTICO ADICIONAL: MULTICOLINEALIDAD\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DIAGNÓSTICO: ANÁLISIS DE CORRELACIÓN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calcular matriz de correlación\n",
    "correlation_matrix = X.corr().abs()\n",
    "\n",
    "# Identificar características altamente correlacionadas\n",
    "threshold = 0.9\n",
    "high_corr = np.where(correlation_matrix > threshold)\n",
    "high_corr_pairs = [(correlation_matrix.index[i], correlation_matrix.columns[j], correlation_matrix.iloc[i, j]) \n",
    "                   for i, j in zip(*high_corr) if i != j and i < j]\n",
    "\n",
    "if high_corr_pairs:\n",
    "    print(f\"\\nSe encontraron {len(high_corr_pairs)} pares con correlación > {threshold}:\")\n",
    "    for pair in high_corr_pairs[:10]:  # Mostrar solo primeros 10\n",
    "        print(f\"  {pair[0]} - {pair[1]}: {pair[2]:.4f}\")\n",
    "else:\n",
    "    print(f\"\\nNo se encontraron pares con correlación > {threshold}\")\n",
    "\n",
    "# ===============================\n",
    "# 13. GUARDAR MEJOR MODELO (MODIFICACIÓN)\n",
    "# ===============================\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
